{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPShU7StmxPaU90k5hS7N3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itissandeep98/ML-Assignments/blob/master/ML_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5O3iEtAFqzd",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEo5gx2hZQKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9RJnOQAEAU3",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kS_U4I6EDez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyPreProcessor():\n",
        "  \"\"\"\n",
        "  My steps for pre-processing for the three datasets.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def pre_process(self, dataset):\n",
        "    \"\"\"\n",
        "    Reading the file and preprocessing the input and output.\n",
        "    Note that you will encode any string value and/or remove empty entries in this function only.\n",
        "    Further any pre processing steps have to be performed in this function too. \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    dataset : integer with acceptable values 0, 1, or 2\n",
        "    0 -> Abalone Dataset\n",
        "    1 -> VideoGame Dataset\n",
        "    2 -> BankNote Authentication Dataset\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features)\n",
        "    y : 1-dimensional numpy array of shape (n_samples,)\n",
        "    \"\"\"     \n",
        "\n",
        "    if dataset == 0:\n",
        "      df=pd.read_csv('/content/Dataset.data',delim_whitespace=True,header=None) # data read from file\n",
        "      df.sample(frac=1) # data shuffled\n",
        "\n",
        "      # changed gender values to integers\n",
        "      df[0].replace('M',1,inplace=True)\n",
        "      df[0].replace('F',2,inplace=True)\n",
        "      df[0].replace('I',3,inplace=True)\n",
        "\n",
        "      data=df.to_numpy() # converted dataframe into numpy array\n",
        "      X=data[:,:-1]\n",
        "      y=data[:,-1]\n",
        "\n",
        "    elif dataset == 1:\n",
        "      df=pd.read_csv('/content/VideoGameDataset.csv') # data read from file\n",
        "      df=df[['Critic_Score','User_Score','Global_Sales']] # required colums extracted\n",
        "      df=df.sample(frac=1) # data shuffled\n",
        "\n",
        "\n",
        "      df['Critic_Score'].fillna(df['Critic_Score'].median(), inplace=True) # replaced NaN values with median of the column\n",
        "      df['User_Score'].replace(to_replace = 'tbd', value = np.nan,inplace=True) # replaced the cell with 'tbd' value to NaN value in the colum\n",
        "      df['User_Score']=df['User_Score'].astype(np.float) # converted column from strings to float values\n",
        "      df['User_Score'].fillna(df['User_Score'].median(), inplace=True) # replaced NaN values with median of the column\n",
        "\n",
        "      data=df.to_numpy() # converted dataframe into numpy array\n",
        "      X=data[:,:-1]\n",
        "      y=data[:,-1]\n",
        "\n",
        "    elif dataset == 2:\n",
        "      # Implement for the banknote authentication dataset\n",
        "      df=pd.read_csv('/content/data_banknote_authentication.txt',header=None) # data read from file\n",
        "      df=df.sample(frac=1) # data shuffled\n",
        "      X=df[[0,1,2,3]].to_numpy()\n",
        "      y=df[[4]].to_numpy()\n",
        "      y=y.squeeze()\n",
        "\n",
        "    elif dataset==3:\n",
        "      df=pd.read_csv('/content/Q4_Dataset.txt',delim_whitespace=True,header=None)\n",
        "      X=df[[1,2]].to_numpy()\n",
        "      y=df[[0]].to_numpy()\n",
        "\n",
        "    X=(X-X.mean(axis=0))/X.std(axis=0) # normalized the data \n",
        "\n",
        "    return X, y\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSTeIMNDSrEl",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gofY4sQaGeYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLinearRegression():\n",
        "  \"\"\"\n",
        "\tMy implementation of Linear Regression.\n",
        "\t\"\"\"\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def cross_validation(self,X,y,epoch=1000,alpha=0.01,k=10,lossfunc=1):\n",
        "    \"\"\"\n",
        "    performs k fold cross validation on the given dataset\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features) \n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,)\n",
        "\n",
        "    k : Number of folds the data needs to be splitted into\n",
        "\n",
        "    epoch : Number of times gradient descent has to run\n",
        "\n",
        "    alpha : Learning rate of gradient descent\n",
        "\n",
        "    lossfunc: determines which loss function to call\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "    m=X.shape[0] # number of samples\n",
        "\n",
        "    split_start=0 # initial split's first index\n",
        "    split_end=m//k # initial split's last index\n",
        "\n",
        "    theta_list=[0]*k  # initialized theta\n",
        "    training_loss_list=[0]*k  # initialized list to store all the training loss from every fold\n",
        "    validation_loss_list=[0]*k # initialized list to store all the validation loss from every fold\n",
        "\n",
        "    error_min=float(\"inf\")\n",
        "    idx=0\n",
        "\n",
        "    for i in range(k):\n",
        "\n",
        "      # Extracting X and y for train and test set\n",
        "      X_train=np.concatenate((X[:split_start],X[split_end:]),axis=0)\n",
        "      y_train=np.concatenate((y[:split_start],y[split_end:]),axis=0)\n",
        "\n",
        "      X_test=X[split_start:split_end]\n",
        "      y_test=y[split_start:split_end]\n",
        "\n",
        "      self.fit(X_train,y_train,X_test,y_test,epoch,alpha,lossfunc) # calculating model parameters by running the gradient descent\n",
        "\n",
        "      # storing the results of current fold in the array\n",
        "      theta_list[i]=self.theta\n",
        "      training_loss_list[i]=self.training_loss\n",
        "      validation_loss_list[i]=self.validation_loss\n",
        "\n",
        "      split_start=split_end # updating slice parameters\n",
        "      split_end+=m//k\n",
        "\n",
        "      error=training_loss_list[i][-1]\n",
        "\n",
        "\n",
        "      # if the error in this fold is minimum of all errors seen upto now then update it and store the fold number\n",
        "      if(error<error_min):\n",
        "        idx=i\n",
        "        error_min=error\n",
        "    \n",
        "    # final storing the values associated with minimum error \n",
        "    self.theta=theta_list[idx]\n",
        "    self.training_loss=training_loss_list[idx]\n",
        "    self.validation_loss=validation_loss_list[idx]\n",
        "\n",
        "  def MSE(self,X,y,theta):\n",
        "    \"\"\"\n",
        "    finding Mean Squared Error based on current model parameters\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features)\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,)\n",
        "\n",
        "    theta : Value of theta at which derivative of cost has to be found\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    derv : derivative of cost at the value theta\n",
        "\n",
        "    err  : Error/cost in prediction at the value theta\n",
        "    \"\"\"\n",
        "    m=len(y)\n",
        "\n",
        "    X_trans=np.transpose(X)                                 # Transpose of vector X\n",
        "    err=X.dot(theta)-y\n",
        "    derv =(1/m)*(X_trans.dot(err))                         # Calculates X` * ( X*theta - y )\n",
        "    \n",
        "    return derv,sum(err**2)/m    \n",
        " \n",
        "  def MAE(self,X,y,theta):\n",
        "    \"\"\"\n",
        "    finding Mean Absolute Error based on current model parameters\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features)\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,)\n",
        "\n",
        "    theta : Value of theta at which derivative of cost has to be found\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    derv : derivative of cost at the value theta\n",
        "    err  : Error/cost in prediction at the value theta\n",
        "    \"\"\"\n",
        "    m=len(y)\n",
        "    err=(1/m)*(X.dot(theta)-y)          # Calculates (1/m) *( X*theta - y )\n",
        "    X_trans=X.T                         # Transpose of vector X\n",
        "    epsilon=10**-7                      # epsilon used only for datset-2 where gradient overshoots value and gives nan \n",
        "    derv=(1/m)*(X_trans.dot(abs(err)/(err)))\n",
        "\n",
        "    return derv,np.sum(abs(err))           # returns gradient and sum((1/m) *( | X*theta - y |))\n",
        "\n",
        "  def RMSE(self,X,y,theta):\n",
        "    \"\"\"\n",
        "    finding Root Mean Squared Error based on current model parameters\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features)\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,) \n",
        "\n",
        "    theta : Value of theta at which derivative of cost has to be found\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    derv : derivative of cost at the value theta\n",
        "\n",
        "    err  : Error/cost in prediction at the value theta\n",
        "    \"\"\"\n",
        "    m=len(y)\n",
        "    X_trans=X.T                                          # Transpose of vector X\n",
        "    diff=X.dot(theta)-y                                  # Calculates ( X*theta - y )\n",
        "   \n",
        "    err=((1/m)*np.sum((diff)**2))**0.5                   # Calculates (1/m) *sqrt(sum((X*theta - y)^2))\n",
        "    derv =(1/m)*(X_trans.dot(diff))/err         \n",
        "    \n",
        "    return derv,err\n",
        "\n",
        "\n",
        "  def gradient_descent(self,X,y,X_test,y_test,epochs,alpha,lossfunc):\n",
        "    \"\"\"\n",
        "    Finding theta using the gradient descent method\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "    X_test : 2-dimensional numpy array of shape (n_samples, n_features) which acts as Testing data.\n",
        "\n",
        "    y_test : 1-dimensional numpy array of shape (n_samples,) which acts as Testing labels.\n",
        "\n",
        "    epochs : Number of times gradient descent has to run\n",
        "\n",
        "    alpha : Learning rate of gradient descent\n",
        "\n",
        "    lossfunc: determines which loss function to call\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    theta : Calculated value of theta on given test set (X,y) with learning rate alpha \n",
        "\n",
        "    training_loss: Calculated training loss at every theta\n",
        "\n",
        "    validation_loss: Calculated validation loss at every theta\n",
        "    \"\"\"\n",
        "   \n",
        "    theta= np.zeros((X.shape[1],))                     # created a column vector theta of length equal to number of features in X with all the initial values 0\n",
        "    \n",
        "    training_loss=np.array([])                      # initializing array to store training loss at every value of theta\n",
        "    validation_loss= np.array([])                   # initializing array to store validation loss at every value of theta\n",
        "\n",
        "\n",
        "    for i in range(epochs): \n",
        "      if(lossfunc==1):     # Using RMSE Loss Function\n",
        "        derv,train_loss=self.RMSE(X,y,theta)   \n",
        "      elif(lossfunc==2):   # Using MAE Loss Function\n",
        "        derv,train_loss=self.MAE(X,y,theta)\n",
        "      else:                # Using MSE Loss Function\n",
        "        derv,train_loss=self.MSE(X,y,theta)\n",
        "      training_loss=np.append(training_loss,train_loss)\n",
        "      \n",
        "\n",
        "      if(X_test is not None): # calculate validation loss only if test set is provided\n",
        "        if(lossfunc==1):    # Using RMSE Loss Function\n",
        "          derv_val,val_loss=self.RMSE(X_test,y_test,theta)   \n",
        "        elif(lossfunc==2):  # Using MAE Loss Function\n",
        "          derv_val,val_loss=self.MAE(X_test,y_test,theta)\n",
        "        else:               # Using MSE Loss Function\n",
        "          derv_val,val_loss=self.MSE(X_test,y_test,theta)\n",
        "\n",
        "        validation_loss=np.append(validation_loss,val_loss)\n",
        "\n",
        "      theta=theta-alpha*derv      \n",
        "  \n",
        "    return theta,training_loss,validation_loss\n",
        "\n",
        "  def fit(self, X, y,X_test=None,y_test=None,epoch=400,alpha=0.01,lossfunc=1):\n",
        "    \"\"\"\n",
        "    Fitting (training) the linear model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "    X_test : 2-dimensional numpy array of shape (n_samples, n_features) which acts as Testing data.\n",
        "\n",
        "    y_test : 1-dimensional numpy array of shape (n_samples,) which acts as Testing labels.\n",
        "\n",
        "    epoch : Number of times gradient descent has to run\n",
        "\n",
        "    alpha : Learning rate of gradient descent\n",
        "\n",
        "    lossfunc: determines which loss function to call\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    self : an instance of self\n",
        "    \"\"\"\n",
        "\n",
        "    X=np.concatenate((np.ones((X.shape[0],1)),X),axis=1) # Adding a bias variable i.e columns of 1 to data\n",
        "\n",
        "    if(X_test is not None): # if validation set is provided then add a bias variable i.e columns of 1 to data\n",
        "      X_test=np.concatenate((np.ones((X_test.shape[0],1)),X_test),axis=1)\n",
        "   \n",
        "    X_trans=np.transpose(X)\n",
        "    if(lossfunc==4):\n",
        "      try:\n",
        "        self.theta = np.linalg.inv(X_trans.dot(X)).dot(X_trans).dot(y)  # using the normal eqn, theta = inv(X`*X)*X`*y\n",
        "      except:\n",
        "        self.theta,self.training_loss,self.validation_loss = self.gradient_descent(X,y,X_test,y_test,epoch,alpha,lossfunc=1) # using the gradient descent method with RMSE loss function(default) if the given data is non invertible\n",
        "    else: \n",
        "      self.theta,self.training_loss,self.validation_loss = self.gradient_descent(X,y,X_test,y_test,epoch,alpha,lossfunc) # using the gradient descent method with given number of epochs and learning rate\n",
        "      \n",
        "\n",
        "    # fit function has to return an instance of itself or else it won't work with test.py\n",
        "    return self\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Predicting values using the trained linear model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    y : 1-dimensional numpy array of shape (n_samples,) which contains the predicted values.\n",
        "    \"\"\"\n",
        "\n",
        "    X=np.concatenate((np.ones((X.shape[0],1)),X),axis=1)\n",
        "\n",
        "    y=np.dot(X,self.theta)\n",
        "\n",
        "    # return the numpy array y which contains the predicted values\n",
        "    return y\n",
        "\n",
        "  def plot_loss(self): # prints and plots all the class variables and regression results\n",
        "    print(\"Thetas:\",self.theta)\n",
        "    print(\"Training Loss:\",self.training_loss[-1])\n",
        "    print(\"Validation Loss:\",self.validation_loss[-1])\n",
        "    \n",
        "    plt.plot(self.training_loss,color=\"g\", label=\"Training Loss\")\n",
        "    plt.plot(self.validation_loss,color=\"r\",label=\"Validation Loss\")\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E68z99ULqRBt",
        "colab_type": "text"
      },
      "source": [
        "## Dataset1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FrZ20anXvGL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67ed50a2-d8c1-4edc-acc1-28c01dfbab2b"
      },
      "source": [
        "preprocessor = MyPreProcessor()\n",
        "X, y = preprocessor.pre_process(0)\n",
        "\n",
        "linear = MyLinearRegression()\n",
        "linear.fit(X,y, lossfunc=4)\n",
        "print(linear.theta)\n",
        "linear.cross_validation(X,y,epoch=10000,alpha=0.01,lossfunc=2)\n",
        "linear.plot_loss()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4177, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0--8rgUVMyfD",
        "colab_type": "text"
      },
      "source": [
        "### Parameters Using Normal Equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeJIZ5tNFbmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc0d417d-ea30-4b1b-bcc2-dc23d52c285d"
      },
      "source": [
        "preprocessor = MyPreProcessor()\n",
        "X, y = preprocessor.pre_process(0)\n",
        "X=np.concatenate((np.ones((X.shape[0],1)),X),axis=1)\n",
        "X_test=X[:X.shape[0]//9]\n",
        "y_test=y[:y.shape[0]//9]\n",
        "\n",
        "X_train=X[X.shape[0]//9:]\n",
        "y_train=y[y.shape[0]//9:]\n",
        "theta=np.array([ 9.93368446 ,-0.3215536,  -0.09923279,  1.18716678 , 0.46859482,  4.44739825,\n",
        " -4.46228469, -1.11301053,  1.21107218])\n",
        "print(X_test.shape)\n",
        "val_loss=sum(abs(X_test.dot(theta)-y_test))/y_test.shape[0]\n",
        "train_loss=sum(abs(X_train.dot(theta)-y_train))/y_train.shape[0]\n",
        "print(train_loss,val_loss)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(464, 9)\n",
            "1.5409430714877588 1.932138018475601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HHOIS1Wb9tpj"
      },
      "source": [
        "## Dataset2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpSzdHFk9tpz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "89a5327c-5041-4b06-c161-b9fa754952d3"
      },
      "source": [
        "preprocessor = MyPreProcessor()\n",
        "X, y = preprocessor.pre_process(1)\n",
        "\n",
        "linear = MyLinearRegression()\n",
        "linear.cross_validation(X,y, epoch=10000,alpha=0.001, lossfunc=2)\n",
        "linear.plot_loss()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thetas: [ 0.18793102  0.05174471 -0.01912461]\n",
            "Training Loss: 0.44689430360711124\n",
            "Validation Loss: 0.5764138583769058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEMCAYAAAAWDss+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de1yUZf7/8dfcwwygQJwGHDyEWSml5Sk7ePhWapKhUFmah+pramrF5roKnUClMmyzg4pb/Qx1t3bt4Bc2pIOWlWi6WpYHrAwxXR0ODqAgIszM/fsDnSREh8PMIPN57j4eDPd93fd9fWTizXXd99y3RlVVFSGEEMIJFHd3QAghRNslISOEEMJpJGSEEEI4jYSMEEIIp5GQEUII4TQSMkIIIZxGQkYIIYTTeLm7A61FaelJbLbGf2QoJMQPs7nCCT1qvaRmzyA1e4am1qwoGoKC2l+0nYTMGTab2qSQObutp5GaPYPU7BmcWbPLQiY/P5/ExETKysoIDAwkNTWVyMjIeu2ys7NZvnw5qqqi0WhIT08nNDSUJUuW8N577xEWFgZA3759SU5OBuDUqVM89dRT7N27F61WS0JCArfddpurShNCCNEAl4VMcnIy48ePJzY2lszMTJKSkli9enWdNrt372bp0qWsWrUKg8FAeXk5er3evj4uLo6EhIR6+16xYgV+fn6sX7+egwcPMmHCBD7//HPat7/4UE4IIYTzuCRkzGYzubm5pKenAxATE0NKSgolJSUEBwfb261cuZLJkydjMBgA8Pf3d2j/n3zyCS+99BIAkZGR9OzZk2+++YY777yzhSsRQvyRqqqUlhZTXV0FXNpTTUVFCjabzd3dcKkL16xBr/chKMiARqNp0v5dEjImk4nw8HC0Wi0AWq2WsLAwTCZTnZDJy8ujU6dOTJgwgcrKSoYPH86MGTPsxa1bt46cnBwMBgNPPPEEffr0AeDo0aN07NjRvh+j0UhBQYErShPC41VUHEej0RAe3gmN5tK+YNXLS8Fi8ayQuVDNqmqjrOwYFRXH8fcPbNr+m9O5lma1Wvn5559JT0+nurqaKVOmEBERQVxcHOPGjWP69OnodDo2b97MzJkzyc7OJigoqEWOHRLi1+RtDQbHRlxtidTsGRyp2Ww+SkhIOF5ererXSZN5eV3aQdkUDdesEBQUQklJIQZD56btu+ndcpzRaKSwsBCr1YpWq8VqtVJUVITRaKzTLiIigujoaPR6PXq9nqFDh7Jr1y7i4uLsU2gAAwcOxGg0sn//fgYMGEBERARHjhyxj4pMJhM33nhjo/poNlc06QoLg8Gf4uLyRm93KZOaPYOjNdfU1KCqbWMEICOZ+lRVobq6pt57QVE0Dv1x7pLIDgkJISoqiqysLACysrKIioqqM1UGtedqcnJyUFWVmpoatm7dSo8ePQAoLCy0t9u3bx9Hjhyha9euAERHR7NmzRoADh48yO7duxk8eLDT66rY9QM/PDkb1Wp1+rGEaM2aOl8vWr/m/mxdNr6dN28eiYmJpKWlERAQQGpqKgBTp04lPj6eXr16cdddd7Fnzx5GjhyJoigMGjSIMWPGALB48WL27t2LoijodDoWLVpkH9088sgjJCYmMnz4cBRFYcGCBfj5NX36y1E1RUWczD+I7dQptC44nhDiwqZOfYiamhoslhoOHz5E167dALj66u48/XSyQ/vIyPiQ06dPM3bshAu2y8n5mh9//IHHHvtTs/t91gsvzKNHjyjuvXdsi+3T3TTyZMxaTZkuK/v6K4r+vpKuL7+KroXODV0KZOrIMzhac0HBb3TocLkLeuQ4k+koU6ZMYt26L+qts1gsDZ4/cvd0mTtCxpGaz/czdnS6rG2cqXMTRa8DQK2udnNPhBAXMmbMKIYOvYPvv9/OFVdcybRpM5k37xlOnjxJdXU1t9wykJkza0ckK1a8yalTp3j88SfJzv6Y9es/xd8/gAMH8vD39+P55xcREhJKdvbHbNmyieefX8T33+/gjTcWc80117J3725Aw/z5LxIZWTul/+aby/jyy/UEBFxGnz79+O677axY8XeH+79v315ee+2vVFWdwsfHlyef/AtRUddSWlrCvHnPUlpqBqB//wHEx89m9+4fefXVRdhsKhaLhYcemszw4dEt/u/qCAmZZtDoaj8oqtZIyAgBsM30Hd+atjtl3zcbb+BGY78mb3/y5Enefrv2A+CnT58mNfVV2rVrh8Vi4c9/fpytW7cwaNCgetvt25fLqlX/JDy8A6mpz/Phh2t49NHH6rXLz8/j6aeTmDv3GVatWsGqVStITn6enJxv2LIlh5Ur/4m3tzfPPlv/A+UXUlNTwzPPzOXpp5Pp338A27dv45ln5rJmTQaff/4JHTt25PXX0wA4ceIEAO++u4oHHpjE8OHRqKpKRYX77sfmedfqtSDNmZGMTUYyQrR60dF32V/bbDbS0l7noYce4JFHJnLgQB779/9y3u2uu+56wsM7AHDttT05evS/523XpcvlXH11jzPtenHkSG27nTt3cPvtw/D19UVRFO68867zbt+QQ4d+Q6fT0b//AABuuOFGdDodhw79xrXX9mLr1i0sW/Y6mzdvol27dgD07dufVaveYeXK/0du7l6HP9juDDKSaQZF7w3IdJkQZ91o7Nes0YYztWvna3+9Zs27lJef4K23VuLt7U1q6gtUV58+73bn3tpKUWo/gnH+dt7ntFMabNeSeva8jvT0d9m+fRuffZbNP/6xkuXLV3D//eMZOHAI27dv47XXFnHDDTcxbdpMp/fnfGQk0wwa3ZlzMjU1bu6JEKIxysvLCQkJxdvbm+LiInJyvnbasfr06cdXX31BVVUVNpuNzz7LbtT2XbpcTk1NDd9/vwOA777bjsVioUuXyzl69Ajt2/sxbNgInnhiFj///BM2m41Dh36jY8dOxMXdy333PcC+fXudUZpDZCTTDMqZv3BkukyIS8t9943juecSmDTpfgyGcPr1u8Fpxxo06H/YvXsXDz00joCAAK69thfl5Q1ftff223/jH/9YZf9+7tyneeGFRXVO/D//fCo6nY6dO79jzZp3URQtqmpjzpynUBSFDz/8F99//x06nRc6nZ5Zs+Y4rb6LkUuYz2jKJczVBQUcfDaRDlOmEXDTLU7qWesjl/N6hkv5EuamctYlzJWVJ2nXrj02m42XXkohNNTgtumrP5JLmFsxjf0SZpkuE0I0LCUlmYKCo5w+fZru3aOYMOFBd3fJZSRkmkE5cwmzTS5hFkJcwMKFf3V3F9xGTvw3g+bMORkZyQghxPlJyDTD2avLbA1c+iiEEJ5OQqYZNIqCRqeTS5iFEKIBEjLNpOj18mFMIYRogIRMMyl6vZz4F0KIBkjINJPWWy8n/oVoJWbPjicj48M6y1RV5b77Ytm587sGt3vhhXl89FHtgw8zMj5kzZp3z9suO/tjnn127kX78c03X5Gbu8f+/U8/5TJ//rOOlOCwxx+fxubNm1p0n84gIdNMil4vd2EWopW4667RZGdn1Vm2c+d3KIqG3r37OrSPuLgxF31g2cVs2vRVnVu59OhxDcnJzzdrn5cql31OJj8/n8TERMrKyggMDCQ1NZXIyMh67bKzs1m+fDmqqqLRaEhPTyc0NJRly5aRnZ1tfzLmrFmz7I9YTkxMZMuWLQSdeXBYdHQ0M2bMcEldirc3NhnJCAHAiS2bOZ7zjVP2fdmgIQTcMvCCbQYP/h9eeWUhBw/m25/lsm7dvxk5chQHDuTxyisvUVV1iurqakaPvpv77x9fbx/nPk+mpqaGV1+tfV7MZZcFctVV3e3t8vJ+Pe/+tm37lpycb9ix4z98/HEmY8eOJzy8A8uWvW5/hswnn2Txz3/+HY1GQ0REJ+bOfZqgoOALPr/GUVu3buHNN5dis9kIDAxizpyn6dSpM4cOHeSFF+afuYealTvvHMX48ZP45puv+Nvflp25+aeFWbPm0rdvf4ePdzEuC5nk5GTGjx9PbGwsmZmZJCUlsXr16jptdu/ezdKlS1m1ahUGg4Hy8nL7HVCvu+46Jk+ejK+vLz/99BMTJ04kJycHHx8fAKZNm8bEiRNdVY6dotdjlZGMEK2CTqdj+PA7yc7+NzNn/onKypNs2vQ1//jH+/j5+fHaa2no9XoqKyuZNu0hBgy42R5G55OZ+REm01H+8Y8PsFgsPPbYVIxGIwBGo/G8+7vxxpsZNGhInSdcnr25JcCBA7/yt78tZcWKfxAaGsrbby/n1VdfZsGChYDjz685n9LSEp5/PoklS96ia9cryMrKYP78Z3n77VWsXfshgwYNYdKk/wV+f/bMW28tZ+7cZ+jZ8zqsVitVVaca/w9/AS4JGbPZTG5uLunp6QDExMSQkpJCSUkJwcHB9nYrV65k8uTJGAwGgDrPQDg7agHo3r07qqpSVlZGhw4dXFFCgxS9HrXyhFv7IERrEXDLwIuONpztrrtG85e/PMGjjz7OF1+sp1ev6wkLC6ekxMzSpS/x66+/oNEoHDtWzK+//nLBkPn++++4884YvLy88PLyYsSIO9m16wcAqqqqGr2/2n3u4OabBxIaWjs6iY29h4cf/n1E9cfn12zfvs3h2vfu3UO3blfTtesVAIwcOZpXXkmlsvIkvXv3IS3tDaqqqujbt799tNK//w288cZibr31dm666RauuOJKh4/nCJeEjMlkIjw8HK1WC4BWqyUsLAyTyVQnZPLy8ujUqRMTJkygsrKS4cOHM2PGDDQaTZ39ZWRk0KVLlzoBk56ezpo1a+jcuTOzZ8+mW7dujeqjIzd6O59jej2KzYLB4L6HArmDp9ULUnNDiooUvLxaz+ndqKgehIYa2L79W7KzP2bcuPF4eSm8/XYaoaGhJCXNx8vLi/j4mVgsNXh5KWg0GhSl9veMotS+rl2O/fXZdRqNxuH9nd1Oq63dl5eXgqIo9n0Adb4qigZvb+9zlnlhs9nO+++r0WjQajV11mm1GvtxAGy2s8sVhg0bzvXX92bbtm95991VZGf/m/nzX+DJJ//Cr7/u57vvtvPcc4k88MBE4uLuqXMsRVGa/P5vVfcus1qt/Pzzz6Snp1NdXc2UKVOIiIggLi7O3uY///kPr7/+Ou+884592axZszAYDCiKQkZGBlOmTGHDhg32UHNEU+7CDKD19aX6ZKVH3aFX7kjsGRyt2WazOeXOxc0xcuRo3n77TQoLTdxyyxAsFhsnTpyga9crAYVffvmFH37YybBhI7BYbKiqav/v32arfW2x2Ojbtz/Z2eu49dZhWK0WPvvsE8LDO1x0f+3atePEiXL7v4vVakNVwWKx0bt3X1ateofCwiJCQkL5v/9byw03DMBisWGzqaiqat/uj9+fS1VVrNa663r06Mmvv/5CXt4BLr88knXr/s1VV3XH29uXgwd/IyKiI9HRMUREdOLFFxdgsdg4cuQQkZHdiIzsRkXFSfbu3UtMTFydY9lstnrvhVZ1F2aj0UhhYSFWqxWttvbJckVFRfa5zbMiIiKIjo5Gr9ej1+sZOnQou3btsofMzp07mTNnDmlpaVxxxRX27cLDw+2v4+LiWLhwIQUFBXTs2NHptXm1b4etsmXnMIUQzTN8eDTLlr3O6NF3oztz+6eHHnqElJQk1q3LpHPnLvTu3eei+xk9+h5+/fVXJk68j8suC6RHj2spLTVfdH8jRozkhRfms3HjF/YT/2ddccWVTJ/+OLNmPXbmxH9H5sx5ukl1vvjivDpP5Hz55dd59tkFzJ//DFarlcDAIJKSUgD48sv1fP75p+h0Xmg0Gv70p9kApKUt4dCh39BqvfDz8+Opp5Ka1JeGuOx5MpMmTWLMmDH2E/8ffvghf//73+u0+fjjj/n66695+eWXsVgsTJ8+nREjRnD//feza9cu4uPjef3117n++uvrbFdYWGgPmk2bNjF37lw2bdqEl5fjGdrUkUzlZx/z34/+j6veXFFvWq+tkr/qPYM8T8YztJnnycybN4/ExETS0tIICAggNTUVgKlTpxIfH0+vXr2466672LNnDyNHjkRRFAYNGsSYMWMAmD+/9tK7pKTfU3bRokV0796dhIQEzGYzGo0GPz8/li9f3qiAaQ5tu3Zgs6GePo3mzJVuQgghasmTMc9o6kjG+v235KW9SddFi9GdcxFDWyZ/1XsGGcl4BmePZFrPJSGXKK/27QGwnZLzMsJzyd+qbVdzf7YSMs2kbdcOANupSjf3RAj3OPtJcdE2Wa0WFMXxK3X/SEKmmWQkIzydr68f5eVlqKpnTTN5AlW1UV5eiq9v0z5HCK3sczKXorMjGWuljGSEZ/Lzu4zS0mIKC/8LXNrTZoqiYLN5VlheuGYNer0Pfn6XNXn/EjLNJNNlwtNpNBqCg8Pc3Y0WIRd4tDyZLmsmLz+ZLhNCiIZIyDSTotej8fLCevKku7sihBCtjoRMM2k0GrQBAVhPHHd3V4QQotWRkGkB2oDLsByXkBFCiD+SkGkBXgEBWE/IM2WEEOKPJGRagDbgMiwSMkIIUY+ETAvwCgjAWn4C1cOurxdCiIuRkGkB2oDLwGbDerLC3V0RQohWRUKmBXgFBADIeRkhhPgDCZkWoL2s9pYLEjJCCFGXy0ImPz+fsWPHMmLECMaOHcvBgwfP2y47O5tRo0YRExPDqFGjOHbsGABWq5X58+czbNgwhg8fzgcffGDf5kLrXOHsSMZyvMylxxVCiNbOZfcuS05OZvz48fbHLyclJbF69eo6bXbv3s3SpUtZtWoVBoOB8vJy9Ho9UPto5kOHDvH5559TVlZGXFwcN998M506dbrgOlfQBgYBYCmVkBFCiHO5ZCRjNpvJzc0lJiYGgJiYGHJzcykpKanTbuXKlUyePBmDwQCAv78/3t7eQO0I57777kNRFIKDgxk2bBiffvrpRde5gtbXF6Vde2rMx1x2TCGEuBS4JGRMJhPh4eFotbUPvtFqtYSFhWEymeq0y8vL4/Dhw0yYMIG7776btLQ0+1PZTCYTERER9rZGo5GCgoKLrnMVXWgoNceKXXpMIYRo7VrVrf6tVis///wz6enpVFdXM2XKFCIiIoiLi3P6sR15VnVDDAZ/zB2NVB46hMHg34K9ar08pc5zSc2eQWpuWS4JGaPRSGFhIVarFa1Wi9VqpaioCKPRWKddREQE0dHR6PV69Ho9Q4cOZdeuXcTFxWE0Gjl69CjXXXcdUHf0cqF1jjKbK7DZGv/ApbPPYrAFBFJVuIOiwuNolLZ90Z48c8MzSM2eoak1K4rGoT/OXfLbMCQkhKioKLKysgDIysoiKiqK4ODgOu1iYmLIyclBVVVqamrYunUrPXr0ACA6OpoPPvgAm81GSUkJGzZsYMSIERdd5yr6DkZUi4WaY3JeRgghznLZdNm8efNITEwkLS2NgIAAUlNTAZg6dSrx8fH06tWLu+66iz179jBy5EgURWHQoEGMGTMGgNjYWH788UfuuOMOAB577DE6d+580XWuou9YeyVb9ZH/og9rG08JFEKI5tKoZ8+se7hmT5dVneLXx2cQEncPITGjndDD1kOmFDyD1OwZ2sR0mSdQfHzxCg3l9H8Pu7srQgjRakjItCDfrldQdSDP3d0QQohWQ0KmBfl0uxJLSQk1paXu7ooQQrQKEjItyOeKKwGoytvv5p4IIUTrICHTgny6dEHx9eXk3j3u7ooQQrQKEjItSOPlRbtrruXk7l3IRXtCCCEh0+LaX9cba1kZVfkH3N0VIYRwOwmZFubXpy8avZ4Tm3Pc3RUhhHA7CZkWpm3XDr9+/Sn/z1Zsp0+7uztCCOFWEjJOEDjkNmynTnH866/c3RUhhHArCRkn8L3qKnx7RFHy6ToZzQghPJqEjJOExt2D9cQJjq390N1dEUIIt5GQcRLfK68i8PZhlH2xnopdP7i7O0II4RYSMk4Ueu99eHfugmn5Mir35bq7O0II4XISMk6keHvT6c9z0IWF89/XXuHY/32ErabG3d0SQgiXkZBxMq2/P53nPkXAjTdRsu5jDj6TiDnr31QXFbm7a0II4XQuezJmfn4+iYmJlJWVERgYSGpqKpGRkXXaLFmyhPfee4+wM0+W7Nu3L8nJyQA8/PDDlJ65u7HVamX//v1kZmbSo0cPEhMT2bJlC0FBQUDt45hnzJjhqtIuStu+PR0mT8X/plsoyc7CnLEWc8ZavLtcju9VV+PTtSs+Xa/AKzgERadzd3eFEKLFuOzJmA8++CD33nsvsbGxZGZm8tFHH7F69eo6bZYsWUJlZSUJCQkX3NeGDRt47bXXyMrKAiAxMZGePXsyceLEJvevuU/GbIwas5nyHf/h5I8/UHUwH7W62r5Oad8er8sC8bosEMXXB41ej+LtjUanR6NVQNGi0SpoFC0oChpFAa229quioNFoQKMBNLU7PPPlfMs0536v0eAof38fysurGlXzebn6/m7NOJyfvw8VjaxZbc4Bm6oFD+nv7015+cUuwXf1z9C5x/Pz86Gi4pyfs8t/hK49oEano+udQykpb/w0vqNPxnTJSMZsNpObm0t6ejoAMTExpKSkUFJSQnBwcKP39+GHH3Lvvfe2dDddRhcSQvCIOwkecSeq1Ur10SNU/fYblrJSLMfLsJYdx3K8DMvxMtTqamzVp1Grq1FtNlSrFWw21/+CPkeh247sPp5YsydO6HpczRoNhqsiIbyL0w7hkpAxmUyEh4ej1WoB0Gq1hIWFYTKZ6oXMunXryMnJwWAw8MQTT9CnT58664uLi/n222958cUX6yxPT09nzZo1dO7cmdmzZ9OtWzfnFtVCNFot3p274N25cT9k1WYDmw1VtYHVhmqz1n5V1XMCSD3nS+3r31ed08aeVyq/D30aFhLSHrP5ZKP62yDHB1AtpGkHDAnxw2yuaMLhXF5gix0yONiPkhJHanZxjU483Pl/zq6uz3XH02i1XBbZodGzMY3hsnMyjhg3bhzTp09Hp9OxefNmZs6cSXZ2tv1cC0BGRgaDBw+uE06zZs3CYDCgKAoZGRlMmTKFDRs22EPNEY4M+xpiMPg3edtLVYTB4O4uuFxEaIi7u+ByxpDGzzRc6ozn/L7xFM78HeaSkDEajRQWFmK1WtFqtVitVoqKijAajXXaGc75xTVw4ECMRiP79+9nwIAB9uVr165l7ty5dbYLDw+3v46Li2PhwoUUFBTQsWNHh/voynMylzqp2TNIzZ6hqTU7ek7GJZcwh4SEEBUVZT9Rn5WVRVRUVL2pssLC32e+9+3bx5EjR+jatat92ffff095eTlDhgxpcLtNmzahKEqd4BFCCOEeLpsumzdvHomJiaSlpREQEEBqaioAU6dOJT4+nl69erF48WL27t2LoijodDoWLVpUZ3Szdu1a4uLi6k2DJSQkYDab0Wg0+Pn5sXz5cry8WtVMoBBCeCSXXcLc2sl0meOkZs8gNXuGNjFdJoQQwjNJyAghhHAaCRkhhBBOIyEjhBDCaSRkhBBCOI2EjBBCCKeRkBFCCOE0EjJCCCGcRkJGCCGE00jICCGEcBoJGSGEEE4jISOEEMJpJGSEEEI4jcMhs3XrVg4fPgxAUVERCQkJPPXUUxQXFzutc0IIIS5tDofM/Pnz7c9xSU1NxWKxoNFoeO6555zWOSGEEJc2h5/sVVhYSEREBBaLhZycHL788kt0Oh2DBw92Zv+EEEJcwhwOGT8/P44dO8b+/fvp1q0b7du3p7q6GovF4tD2+fn5JCYmUlZWRmBgIKmpqURGRtZps2TJEt577z3CwsIA6Nu3L8nJyQAkJiayZcsWgoKCAIiOjmbGjBkAHDt2jLlz53LkyBG8vb1JSUnh+uuvd7Q0IYQQTuJwyEycOJExY8ZQU1PD008/DcD333/PFVdc4dD2ycnJjB8/ntjYWDIzM0lKSmL16tX12sXFxZGQkHDefUybNo2JEyfWW/7KK6/Qv39/3nnnHXbs2MGcOXP47LPP0Gg0jpYnhBDCCRwOmWnTpjF8+HC0Wi1dunQBIDw8nOeff/6i25rNZnJzc0lPTwcgJiaGlJQUSkpKCA4ObmLXf/fpp5/yxRdfANC/f3/0ej27d+/muuuua/a+hRBCNJ3DIQPQtWtX++utW7eiKAoDBgy46HYmk4nw8HD7hQNarZawsDBMJlO9kFm3bh05OTkYDAaeeOIJ+vTpY1+Xnp7OmjVr6Ny5M7Nnz6Zbt26Ulpaiqmqd/RiNRgoKChoVMo48q7ohBoN/k7e9VEnNnkFq9gzOrLlR02WzZs2iX79+vPXWW6xcuRKtVsuECROYPn16i3Rm3LhxTJ8+HZ1Ox+bNm5k5cybZ2dkEBQUxa9YsDAYDiqKQkZHBlClT2LBhQ4scF8BsrsBmUxu9ncHgT3FxeYv141IgNXsGqdkzNLVmRdE49Me5w5cw79+/n969ewPwwQcfsHr1at5//33+9a9/XXRbo9FIYWEhVqsVAKvVSlFREUajsU47g8GATqcDYODAgRiNRvbv3w/UTs0pSm134+LiqKyspKCgwH4hQElJiX0/JpOJDh06OFqaEEIIJ3E4ZGw2GxqNhkOHDqGqKldeeSVGo5Hjx49fdNuQkBCioqLIysoCICsri6ioqHpTZYWFhfbX+/bt48iRI/YpunPXbdq0CUVRCA8PB2qvNDsbdjt27KCqqoqePXs6WpoQQggncXi6rF+/fixYsIDi4mKGDx8OwKFDh+wjiYuZN28eiYmJpKWlERAQQGpqKgBTp04lPj6eXr16sXjxYvbu3YuiKOh0OhYtWoTBYAAgISEBs9mMRqPBz8+P5cuX4+VV2/3Zs2czZ84cMjIy8Pb2ZtGiRfZRjxBCCPfRqKrq0ImI0tJS0tPT8fLy4pFHHqF9+/Z89dVXHDx4kIcfftjJ3XQ+OSfjOKnZM0jNnsHZ52QcHskEBQXx5z//uc6yW2+9tdEdE0II4TkcnlOqqanhjTfeYOjQofTq1YuhQ4fyxhtvUF1d7cz+CSGEuIQ5PJJ5+eWX2bVrF/PnzyciIoKjR4+SlpZGRUWF/Q4AQgghxLkcDplPP/2UzMxM+4n+K664gmuuuYbY2FgJGSGEEOfl8HRZQ9cHOHjdgBBCCA/kcMicvevxpkM4M4sAABlOSURBVE2byMvL45tvvuGxxx7jzjvvdGb/hBBCXMIcni6bM2cOy5cvZ8GCBRQVFREeHs7IkSPlxL8QQogGOfw5mfM5ffo0vXv3Zt++fS3ZJ7eQz8k4Tmr2DFKzZ2g19y47H41GI+dkhBBCNKjZ916RB4MJIYRoyEXPyXz77bcNrqupqWnRzgghhGhbLhoyzzzzzAXX//F2/UIIIcRZFw2ZL7/80hX9EEII0QbJ/fCFEEI4jYSMEEIIp5GQEUII4TQOf+K/ufLz80lMTKSsrIzAwEBSU1OJjIys02bJkiW89957hIWFAdC3b1+Sk5MBmD9/Pt9++y16vZ527drxzDPP0KtXLwAmTZrE0aNH8fOr/WDQgw8+yL333uuq0oQQQjTAZSGTnJzM+PHjiY2NJTMzk6SkJFavXl2vXVxcHAkJCfWWDxkyhKeffhqdTsfGjRuZNWsWGzZssK9/9tlnue2225xagxBCiMZxyXSZ2WwmNzeXmJgYAGJiYsjNzaWkpMThfdx2223odDoAevfuTUFBATabzSn9FUII0TJcMpIxmUyEh4ej1WoB0Gq1hIWFYTKZCA4OrtN23bp15OTkYDAYeOKJJ+jTp0+9/b377rvceuutKMrvGblo0SIWL15M9+7dmTNnDuHh4Y3qoyP34GmIweDf5G0vVVKzZ5CaPYMza3bZdJkjxo0bx/Tp09HpdGzevJmZM2eSnZ1tf1Aa1IbQxx9/zLvvvmtftmjRIoxGI1arlTfffJMnn3ySf/7zn406ttwg03FSs2eQmj1Dq75BpqOMRiOFhYVYrVYArFYrRUVF9e4WYDAY7FNiAwcOxGg0sn//fvv69evX8+qrr7JixQpCQ0Pr7B9qR0gPPvggP/74o0ylCSFEK+CSkAkJCSEqKoqsrCwAsrKyiIqKqjdVVlhYaH+9b98+jhw5QteuXQHYuHEjCxcuZMWKFXTq1MnezmKxcOzYMfv369at4+qrr64zleYspVVlfJGX4/TjCCHEpcpl02Xz5s0jMTGRtLQ0AgICSE1NBWDq1KnEx8fTq1cvFi9ezN69e1EUBZ1Ox6JFizAYDAA89dRT6HQ64uPj7ftcuXIl3t7eTJs2zX6zzrCwMBYvXuySmnYW7+aj/R/zypDu+Hj5uOSYQghxKWnWQ8vakqack/nmv1tY80sGCwc9R4Dec04Wyry1Z5CaPUObOCfTVumU2vNHNVZ55IEQQpyPhEwz6LRnQsYmISOEEOcjIdMMZ0cy1RIyQghxXhIyzaC3T5dZ3NwTIYRonSRkmkGmy4QQ4sIkZJpBp9ReAV5trXZzT4QQonWSkGkG+9VlMpIRQojzkpBpBr1WD0C1Tc7JCCHE+UjININ8TkYIIS5MQqYZ9NraczIyXSaEEOcnIdMMck5GCCEuTEKmGbQaLRqNRqbLhBCiARIyzaDRaNBr9fKJfyGEaICETDPptTpq5OoyIYQ4LwmZZtJrdTJdJoQQDXBZyOTn5zN27FhGjBjB2LFjOXjwYL02S5Ys4eabbyY2NpbY2Fjmz59vX3fq1CmefPJJhg8fTnR0NBs3bnRonbPVjmQkZIQQ4nxc9mTM5ORkxo8fT2xsLJmZmSQlJbF69ep67eLi4khISKi3fMWKFfj5+bF+/XoOHjzIhAkT+Pzzz2nfvv0F1zmbnJMRQoiGuWQkYzabyc3NJSYmBoCYmBhyc3MpKSlxeB+ffPIJY8eOBSAyMpKePXvyzTffXHSds8l0mRBCNMwlIWMymQgPD0er1QKg1WoJCwvDZDLVa7tu3TpGjRrF5MmT2blzp3350aNH6dixo/17o9FIQUHBRdc5m0yXCSFEw1w2XeaIcePGMX36dHQ6HZs3b2bmzJlkZ2cTFBTk9GM78qzq89Fr9ZxSqjAY/Fu4R62bp9ULUrOnkJpblktCxmg0UlhYiNVqRavVYrVaKSoqwmg01mlnMBjsrwcOHIjRaGT//v0MGDCAiIgIjhw5QnBwMFA7OrrxxhsBLrjOUWZzBTab2ujavLV6Kk9XUVxc3uhtL1UGg79H1QtSs6eQmh2nKBqH/jh3yXRZSEgIUVFRZGVlAZCVlUVUVJQ9FM4qLCy0v963bx9Hjhyha9euAERHR7NmzRoADh48yO7duxk8ePBF1zmbr86HKutplxxLCCEuNS6bLps3bx6JiYmkpaUREBBAamoqAFOnTiU+Pp5evXqxePFi9u7di6Io6HQ6Fi1aZB/dPPLIIyQmJjJ8+HAURWHBggX4+flddJ2ztdP5cspyyiXHEkKIS41GVdXGzxG1QU2dLvuq8Gs+2LuOJbe9hKLxjM+2ypSCZ5CaPUObmC5ry3x1vgBUWarc3BMhhGh9JGSaqd2ZkDllkfMyQgjxRxIyzdRO5wNAlVVGMkII8UcSMs30+0hGQkYIIf5IQqaZfg8ZucJMCCH+SEKmmdrpZSQjhBANkZBppnZeZ87JSMgIIUQ9EjLNJOdkhBCiYRIyzaTT6tApXpy0VLq7K0II0epIyDSTRqPBT+dHeXWFu7sihBCtjoRMCwjQ+0vICCHEeUjItAB/vR8nqj3rfkdCCOEICZkWEKD3o0JGMkIIUY+ETAvw1/tTXnMSm2pzd1eEEKJVkZBpAf56P2yqjcoa+dS/EEKcS0KmBQToa5+pIOdlhBCiLpc9GTM/P5/ExETKysoIDAwkNTWVyMjI87Y9cOAAd999N+PHjychIQGAhx9+mNLSUgCsViv79+8nMzOTHj16kJiYyJYtWwgKCgJqH8c8Y8YMl9QFtSMZQK4wE0KIP3BZyCQnJzN+/HhiY2PJzMwkKSmJ1atX12tntVpJTk5m2LBhdZavXLnS/nrDhg289tpr9OjRw75s2rRpTJw40Wn9v5AAvT8gIxkhhPgjl0yXmc1mcnNziYmJASAmJobc3FxKSkrqtX3rrbe49dZbGxzlAHz44Yfce++9zupuowV6BwJQWlXm5p4IIUTr4pKQMZlMhIeHo9VqAdBqtYSFhWEymeq0++mnn8jJyeHhhx9ucF/FxcV8++23xMbG1lmenp7OqFGjmDlzJnl5eS1ew4X4eHnjp2uPuap+aAohhCdz2XTZxdTU1PDcc8+xcOFCexidT0ZGBoMHDyY4ONi+bNasWRgMBhRFISMjgylTprBhw4YL7uePQkL8mtx3g8GfML8Qym3lGAz+Td7PpcRT6jyX1OwZpOaW5ZKQMRqNFBYWYrVa0Wq1WK1WioqKMBqN9jbFxcUcOnSIadOmAXDixAlUVaWiooKUlBR7u7Vr1zJ37tw6+w8PD7e/jouLY+HChRQUFNCxY0eH+2g2V2CzqY2uzWDwp7i4nACvyzCdKKC4uO2flzlbsyeRmj2D1Ow4RdE49Me5S0ImJCSEqKgosrKyiI2NJSsri6ioqDqjkYiICLZt22b/fsmSJVRWVtqvLgP4/vvvKS8vZ8iQIXX2X1hYaA+aTZs2oShKneBxhRCfIPaa96GqKhqNxqXHFkKI1spl02Xz5s0jMTGRtLQ0AgICSE1NBWDq1KnEx8fTq1evi+5j7dq1xMXF1ZsGS0hIwGw2194R2c+P5cuX4+Xl2pnAUN9gamwWyk4fJ8gn0KXHFkKI1kqjqmrj54jaoOZOl/1SmsfrO9/k8eunEBVytRN62HrIlIJnkJo9g7Ony+QT/y3E2L52es5UWejmngghROshIdNC/HTtaa9rR8FJCRkhhDhLQqaFaDQaItp34L8Vpos3FkIIDyEh04K6BHTiSPlRamwWd3dFCCFaBQmZFhQZ0AWLauWojGaEEAKQkGlRXQO6AHDg+G9u7okQQrQOEjItKMgnkFDfEH4q2e/urgghRKsgIdPCooKv5peyPCxyXkYIISRkWlpU8FVUW6v5tSzf3V0RQgi3k5BpYVHBV6PX6vmu8Ed3d0UIIdxOQqaF6bV6rg/tyc7i3XIpsxDC40nIOMFNxn6cspxie8FOd3dFCCHcSkLGCboHXUknvwg2HPoam2pzd3eEEMJtJGScQKPRMPzyWymsLGKr6Tt3d0cIIdxGQsZJ+oZdR7fLIsn4dR3l1RXu7o4QQriFhIyTKBqFB3rcS5X1NO/sfU8+NyOE8EguC5n8/HzGjh3LiBEjGDt2LAcPHmyw7YEDB7j++uvtT88ESExMZMiQIcTGxhIbG8vy5cvt644dO8bkyZMZMWIEo0eP5scfW8flw8b24UzoMYZfSn/l7/vel6ARQngclz2jODk5mfHjxxMbG0tmZiZJSUmsXr26Xjur1UpycjLDhg2rt27atGlMnDix3vJXXnmF/v37884777Bjxw7mzJnDZ599hkajcUotjXGjsR/HT58g88AnmE+VMLnnBIJ9gtzdLSGEcAmXjGTMZjO5ubnExMQAEBMTQ25uLiUlJfXavvXWW9x6661ERkY6vP9PP/2UcePGAdC/f3/0ej27d+9ukb63hDsib+ORnhMxnSzkhW2Lyc5fT0XNSXd3SwghnM4lIxmTyUR4eDharRYArVZLWFgYJpOJ4OBge7uffvqJnJwcVq9eTVpaWr39pKens2bNGjp37szs2bPp1q0bpaWlqKpaZz9Go5GCggKuu+46h/voyLOqG2Iw+F+0zQjDQK7vchX/+PH/WJe/nvWHvmJQlxvo3/E6rg3rjq/Op8nHdwdHam5rpGbPIDW3LJdNl11MTU0Nzz33HAsXLrSH0blmzZqFwWBAURQyMjKYMmUKGzZsaLHjm80V2Gxqo7czGPwpLi53qK0WXx7qPp5hHW/jq8ObyTm0gy/zt6DVaIkM6EJn/wjC24UR4htMqE8QwT5B6LS6RvfJ2RpTc1shNXsGqdlxiqJx6I9zl4SM0WiksLAQq9WKVqvFarVSVFSE0Wi0tykuLubQoUNMmzYNgBMnTqCqKhUVFaSkpBAeHm5vGxcXx8KFCykoKKBjx44AlJSU2EczJpOJDh06uKK0JunoZ2RC1Bju7x7HgbKD7Cv5hf1lB9hi2k61tbpO2/Ze7fDx8sZb642Plw8+Wm+8vbzxVvR4KVq0ihdeGi1aRXvmqxdajYJGo6H2f6DR1M6K/r5Mg0bDOa81cObrmVf281m1S+oKqPThxImqessbfQaskefMGn+GzfEtLnb+LqDq/DW3ZVJz26dTvPifkP5OPYZLQiYkJISoqCiysrKIjY0lKyuLqKioOlNcERERbNu2zf79kiVLqKysJCEhAYDCwkJ70GzatAlFUezfR0dH869//YuZM2eyY8cOqqqq6NmzpytKaxad4kX34CvpHnwlADbVxonqco6dKsF8qoRjVSVUVFdQZT1NleU0VdbTnKypxFxVwmlrNVbVitVmxXLmq1W1urkiIcSlJjQoAKO2k9P277Lpsnnz5pGYmEhaWhoBAQH2y5OnTp1KfHw8vXr1uuD2CQkJmM1mNBoNfn5+LF++HC+v2u7Pnj2bOXPmkJGRgbe3N4sWLUJRLr2PACkahUDvywj0vowrA7s2entVVbGqViw2K6CinlkGKjZUav9/5n/q718BbGfa1S6zb3FewcHtKSn5w4ULauOmGhs/Mem8/asO9P28NbdxUnPbp1N0XNMh0qlThBrVkf/CPIArzsm0FVKzZ5CaPYOzz8lcen/uCyGEuGRIyAghhHAaCRkhhBBOIyEjhBDCaSRkhBBCOI2EjBBCCKdpNbeVcTdFafodm5uz7aVKavYMUrNnaErNjm4jn5MRQgjhNDJdJoQQwmkkZIQQQjiNhIwQQginkZARQgjhNBIyQgghnEZCRgghhNNIyAghhHAaCRkhhBBOIyEjhBDCaSRkmiE/P5+xY8cyYsQIxo4dy8GDB93dpUYrLS1l6tSpjBgxglGjRvH4449TUlICwA8//MDo0aMZMWIEkydPxmw227dr6rrWZunSpXTv3p1ffvkFaNs1nz59muTkZO644w5GjRrFc889B1z4fdzUda3Fxo0biYuLIzY2ltGjR/P5558Dbafm1NRUbr/99jrvYXBOfU2uXRVNNmnSJDUjI0NVVVXNyMhQJ02a5OYeNV5paam6detW+/cvvfSS+tRTT6lWq1UdNmyYun37dlVVVXXZsmVqYmKiqqpqk9e1Nnv27FEfeeQR9bbbblN//vnnNl9zSkqK+sILL6g2m01VVVUtLi5WVfXC7+OmrmsNbDab2r9/f/Xnn39WVVVV9+3bp/bu3Vu1Wq1tpubt27erR48etb+Hz3JGfU2tXUKmiY4dO6b269dPtVgsqqqqqsViUfv166eazWY396x5Pv30U/Whhx5Sf/zxR/Wuu+6yLzebzWrv3r1VVVWbvK41OX36tHr//ferhw8ftv8H2pZrrqioUPv166dWVFTUWX6h93FT17UWNptNHTBggLpjxw5VVVX1P//5j3rHHXe0yZrPDRln1Nec2uUuzE1kMpkIDw9Hq9UCoNVqCQsLw2QyERwc7ObeNY3NZuOf//wnt99+OyaTiYiICPu64OBgbDYbZWVlTV4XGBjo0nou5PXXX2f06NF06tTJvqwt13z48GECAwNZunQp27Zto3379vzpT3/Cx8enwfexqqpNWtda3v8ajYbXXnuNmTNn0q5dO06ePMlbb711wf92L/Wa4cK/m5paX3Nql3Mywi4lJYV27doxceJEd3fFqXbu3MmePXsYP368u7viMlarlcOHD3PNNdewdu1a/vKXv/DEE09QWVnp7q45jcVi4c033yQtLY2NGzeyfPlynnzyyTZdc2skI5kmMhqNFBYWYrVa0Wq1WK1WioqKMBqN7u5ak6SmpvLbb7/xt7/9DUVRMBqNHD161L6+pKQERVEIDAxs8rrWYvv27eTl5TF06FAACgoKeOSRR5g0aVKbrdloNOLl5UVMTAwA119/PUFBQfj4+DT4PlZVtUnrWot9+/ZRVFREv379AOjXrx++vr54e3u32Zrhwr+bmlpfc2qXkUwThYSEEBUVRVZWFgBZWVlERUW1qmGzoxYvXsyePXtYtmwZer0egJ49e1JVVcWOHTsA+Ne//kV0dHSz1rUW06ZNIycnhy+//JIvv/ySDh06sGLFCqZMmdJmaw4ODubGG29k8+bNQO2VQmazmcjIyAbfxxd6j18K7/8OHTpQUFDAgQMHAMjLy8NsNnP55Ze32Zrhwr+bnLHuolrmtJNn+vXXX9UxY8aod9xxhzpmzBg1Ly/P3V1qtF9++UW9+uqr1TvuuEMdPXq0Onr0aHXmzJmqqqrqd999p8bExKjDhw9XH374YfvVSM1Z1xqde9K0Ldd86NAhdeLEiWpMTIwaFxenfvXVV6qqXvh93NR1rUVmZqYaExOjjho1Sh01apS6fv16VVXbTs0pKSnq4MGD1aioKPWWW25RR44cedF+urp2eTKmEEIIp5HpMiGEEE4jISOEEMJpJGSEEEI4jYSMEEIIp5GQEUII4TQSMkJcwvr06cPhw4fd3Q0hGiQhI0Qz3H777WzZsoW1a9fywAMPOPVYkyZN4oMPPqizbOfOnXTu3NmpxxWiOSRkhGgFLBaLu7sghFNIyAjRTHl5eSQnJ/PDDz/Qp08f+vfvD0B1dTWpqanceuut3HLLLSQlJVFVVQXAtm3bGDJkCG+99RYDBw7kqaee4vjx4zz66KPcdNNN3HDDDTz66KMUFBQA8Oqrr7Jjxw4WLFhAnz59WLBgAQDdu3fnt99+A6C8vJy5c+dy0003cdttt5GWlobNZgOwj7RSU1O54YYbuP322/n6669d/U8lPJCEjBDN1K1bN+bPn0/v3r3ZuXOn/R5mf/3rX8nPzycjI4PPP/+coqIili1bZt/u2LFjHD9+nI0bN5KSkoLNZuOee+5h48aNbNy4EW9vb3uYzJo1i/79+5OUlMTOnTtJSkqq14+UlBTKy8vZsGEDf//738nMzOSjjz6yr9+1axddu3Zl69atTJkyhWeeeQa54YdwNgkZIZxAVVXef/99nn76aQIDA/Hz8+PRRx9l3bp19jaKohAfH49er8fHx4egoCBGjBiBr68vfn5+zJgxg+3btzt0PKvVSnZ2NrNnz8bPz49OnTrxv//7v/z73/+2t4mIiOD+++9Hq9Vy9913U1xczLFjx1q8diHOJbf6F8IJSkpKOHXqFPfcc499maqq9ukrgKCgILy9ve3fnzp1ioULF7Jp0yaOHz8OwMmTJ+23V7+Q0tJSampq6jw8LSIigsLCQvv3oaGh9te+vr4A8mwV4XQSMkK0AI1GU+f7s89qWbduHeHh4Q5t884775Cfn8/777+PwWBg3759xMXFOTSlFRQUhE6n4+jRo1x55ZXA709IFMKdZLpMiBYQEhJCYWEh1dXVQO1U2H333ceLL76I2WwGoLCwkE2bNjW4j5MnT+Lt7U1AQABlZWUsXbq0zvrQ0NAGPxOj1WqJjo7m1VdfpaKigiNHjpCens7o0aNbqEIhmkZCRogWcNNNN3HllVcyaNAgbrzxRgDmzJnD5Zdfzv3330/fvn15+OGHyc/Pb3AfDz30EKdPn+amm25i7NixDB48uM76Bx98kM8++4wbbriB559/vt72zz33HL6+vgwbNozx48cTExPDvffe27KFCtFI8jwZIYQQTiMjGSGEEE4jISOEEMJpJGSEEEI4jYSMEEIIp5GQEUII4TQSMkIIIZxGQkYIIYTTSMgIIYRwGgkZIYQQTvP/ARGm+thHg2w/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU4kz7QRS5AO",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W66BTEUZGh4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLogisticRegression():\n",
        "\t\"\"\"\n",
        "\tMy implementation of Logistic Regression.\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tpass\n",
        "\n",
        "\tdef sigmoid(self,z):\n",
        "\t\t\"\"\"\n",
        "\t\tFind the sigmoid value of z\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tz : 1-dimensional numpy array of shape (n_samples,)\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tvalue of z in sigmoid function\n",
        "\t\t\"\"\"\n",
        "\t\treturn 1/(1+np.exp(-z))\n",
        "\t\n",
        "\tdef accuracy(self,y_hat,y):\n",
        "\t\t\"\"\"\n",
        "\t\tFind the accuracy in predicted data\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\ty_hat : 1-dimensional numpy array of shape (n_samples,), predicted values using regression\n",
        "\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,), Original\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tAccuracy value\n",
        "\t\t\"\"\"\n",
        "\t\tm=y.shape[0]  # number of samples\n",
        "\t\ty_hat[y_hat>=0.5]=1  # if probability of getting 1 is greater than or equal to 0.5 then predict 1\n",
        "\t\ty_hat[y_hat<0.5]=0   # if probability of getting 1 is less than 0.5 then predict 0\n",
        "\t\treturn (1-sum(abs(y-y_hat))/m)*100  # returns the average of difference of values in both arrays\n",
        "\n",
        "\tdef cost_diff(self,X,y,theta):\n",
        "\t\t\"\"\"\n",
        "\t\tFind Log Loss error in current model parameters\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tX : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "\t\ttheta : Value of theta at which derivative of cost has to be found\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tderv : derivative of cost at the value theta\n",
        "\n",
        "\t\terr: error in prediction using the current value of theta\n",
        "\n",
        "\t\taccuracy: accuracy of prediction of data\n",
        "\t\t\"\"\"\n",
        "\t\tm=y.shape[0]\n",
        "\t\tX_trans=X.T\t\t  \t# Transpose of vector X\n",
        "\t\n",
        "\t\tactiv =self.sigmoid(X.dot(theta))\n",
        "\n",
        "\t\tderv =(X_trans.dot(activ-y))\t\t  # Calculates X` * ( sigmoid(X*theta) - y )\n",
        "\n",
        "\t\terr=(-1/m)*(np.sum(y*np.log(activ)+(1-y)*np.log(1-activ+10**-7)))  # calculates the cross entropy loss\n",
        "\n",
        "\t\taccuracy=self.accuracy(activ,y)  # calculates the accuracy\n",
        "\n",
        "\t\treturn derv,err,accuracy\n",
        "\n",
        "\n",
        "\tdef stochastic_gradient_descent(self,X,y,X_test=None,y_test=None,epoch=1000,alpha=0.01):\n",
        "\t\t\"\"\"\n",
        "\t\tFinding theta using the stochastic gradient descent model\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tX : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "\t\tX_test : 2-dimensional numpy array of shape (n_samples, n_features) which acts as Testing data.\n",
        "\n",
        "    y_test : 1-dimensional numpy array of shape (n_samples,) which acts as Testing labels.\n",
        "\n",
        "    epoch : Number of times gradient descent has to run\n",
        "\n",
        "    alpha : Learning rate of gradient descent\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\ttheta : Calculated value of theta on given test set (X,y) with learning rate alpha \n",
        "\n",
        "\t\ttraining_loss: Calculated training loss at every theta\n",
        "\n",
        "    validation_loss: Calculated validation loss at every theta\n",
        "\n",
        "\t\ttraining_loss_acc: Calculated training accuracy at every theta\n",
        "\n",
        "    validation_lossacc_: Calculated validation accuracy at every theta\n",
        "\t\t\"\"\"\n",
        "\t\tm=y.shape[0]\n",
        "\t\t\n",
        "\t\ttheta= np.zeros((X.shape[1],))\t\t  # created a column vector theta of length equal to number of features in X with all the initial values 0\n",
        "\t\t\n",
        "\t\tvalidation_loss_list=np.array([])\n",
        "\t\ttraining_loss_list=np.array([])\n",
        "\t\n",
        "\t\tvalidation_acc_list=np.array([])\n",
        "\t\ttraining_acc_list=np.array([])\n",
        "\t\n",
        "\t\tfor i in range(epoch):\n",
        "\t\t\n",
        "\t\t\tcurr_X=np.array([X[i%m]])\n",
        "\t\t\tcurr_y=np.array([y[i%m]])\n",
        "\t \n",
        "\t\t\tderv,loss,accuracy=self.cost_diff(curr_X,curr_y,theta)\n",
        "\t \n",
        "\t\t\tderv_train,loss_train,accuracy_train=self.cost_diff(X,y,theta)\n",
        "\t \n",
        "\t\t\ttraining_loss_list=np.append(training_loss_list,loss_train)\n",
        "\t\t\ttraining_acc_list=np.append(training_acc_list,accuracy_train)\n",
        "\n",
        "\t\t\tif(X_test is not None):\n",
        "\t\t\t\tderv_val,loss_val,accuracy_val=self.cost_diff(X_test,y_test,theta)\n",
        "\t\t\n",
        "\t\t\t\tvalidation_loss_list=np.append(validation_loss_list,loss_val)\n",
        "\t\t\t\tvalidation_acc_list=np.append(validation_acc_list,accuracy_val)\n",
        "\t\t\n",
        "\t\t\ttheta=theta-(alpha)*derv\n",
        "\t\t\n",
        "\t\treturn theta,validation_loss_list,training_loss_list,validation_acc_list,training_acc_list\n",
        "\n",
        "\n",
        "\t\n",
        "\tdef batch_gradient_descent(self,X,y,X_test=None,y_test=None,epoch=1000,alpha=0.01):\n",
        "\t\t\"\"\"\n",
        "\t\tFinding theta using the batch gradient descent model\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tX : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "\t\tX_test : 2-dimensional numpy array of shape (n_samples, n_features) which acts as Testing data.\n",
        "\n",
        "    y_test : 1-dimensional numpy array of shape (n_samples,) which acts as Testing labels.\n",
        "\n",
        "    epoch : Number of times gradient descent has to run\n",
        "\n",
        "    alpha : Learning rate of gradient descent\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\ttheta : Calculated value of theta on given test set (X,y) with learning rate alpha \n",
        "\n",
        "\t\ttraining_loss: Calculated training loss at every theta\n",
        "\n",
        "    validation_loss: Calculated validation loss at every theta\n",
        "\n",
        "\t\ttraining_loss_acc: Calculated training accuracy at every theta\n",
        "\n",
        "    validation_lossacc_: Calculated validation accuracy at every theta\n",
        "\t\t\"\"\"\n",
        "\t\tm=y.shape[0]\n",
        "\t\t\n",
        "\t\ttheta= np.zeros((X.shape[1],))\t\t  # created a column vector theta of length equal to number of features in X with all the initial values 0\n",
        "\t\t\n",
        "\t\tvalidation_loss_list=np.array([])\n",
        "\t\ttraining_loss_list=np.array([])\n",
        "\t\n",
        "\t\tvalidation_acc_list=np.array([])\n",
        "\t\ttraining_acc_list=np.array([])\n",
        "\n",
        "\t\tfor i in range(epoch):\n",
        "\t\t\tderv_train,loss_train,accuracy_train=self.cost_diff(X,y,theta)\n",
        "\t\t\ttraining_loss_list=np.append(training_loss_list,loss_train)\n",
        "\t\t\ttraining_acc_list=np.append(training_acc_list,accuracy_train)\n",
        "\n",
        "\t\t\tif(X_test is not None):\n",
        "\t\t\t\tderv_val,loss_val,accuracy_val=self.cost_diff(X_test,y_test,theta)\n",
        "\t\t\t\tvalidation_loss_list=np.append(validation_loss_list,loss_val)\n",
        "\t\t\t\tvalidation_acc_list=np.append(validation_acc_list,accuracy_val)\n",
        "\t\t\n",
        "\t\t\ttheta=theta-(alpha)*derv_train\n",
        "\t\t\n",
        "\t\treturn theta,validation_loss_list,training_loss_list,validation_acc_list,training_acc_list\n",
        "\n",
        "\tdef fit(self, X, y,X_test=None,y_test=None,epoch=10000,alpha=0.01,type=0):\n",
        "\t\t\"\"\"\n",
        "\t\tFitting (training) the logistic model.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tX : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "\t\tX_test : 2-dimensional numpy array of shape (n_samples, n_features) which acts as Testing data.\n",
        "\n",
        "    y_test : 1-dimensional numpy array of shape (n_samples,) which acts as Testing labels.\n",
        "\n",
        "    epoch : Number of times gradient descent has to run\n",
        "\n",
        "    alpha : Learning rate of gradient descent\n",
        "\n",
        "\t\ttype : 0 value runs batch gradient descent, else stochastic gradient descent is run \n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tself : an instance of self\n",
        "\t\t\"\"\"\n",
        "\t\tX=np.concatenate((np.ones((X.shape[0],1)),X),axis=1) # Adding a bias variable i.e columns of 1 to data\n",
        "\n",
        "\t\tif(X_test is not None): # if validation set is provided then add a bias variable i.e columns of 1 to data\n",
        "\t\t\tX_test=np.concatenate((np.ones((X_test.shape[0],1)),X_test),axis=1)\n",
        "\t\tif(type==0):\n",
        "\t\t\tself.theta,self.validation_loss,self.training_loss,self.validation_acc,self.training_acc = self.batch_gradient_descent(X,y,X_test,y_test,epoch,alpha)\t\t  # using the batch gradient descent method with given number of epochs and learning rate\n",
        "\t\telse:\n",
        "\t\t\tself.theta,self.validation_loss,self.training_loss,self.validation_acc,self.training_acc = self.stochastic_gradient_descent(X,y,X_test,y_test,epoch,alpha)  # using the stochastic gradient descent method with given number of epochs and learning rate\n",
        "\t\t\n",
        "\t\t# fit function has to return an instance of itself or else it won't work with test.py\n",
        "\t\treturn self\n",
        "\n",
        "\tdef predict(self, X):\n",
        "\t\t\"\"\"\n",
        "\t\tPredicting values using the trained logistic model.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tX : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,) which contains the predicted values.\n",
        "\t\t\"\"\"\n",
        "\t\tX=np.concatenate((np.ones((X.shape[0],1)),X),axis=1)\n",
        "\t\ty=self.sigmoid(X.dot(self.theta))\n",
        "\t\n",
        "\t\ty[y>=0.5]=1\n",
        "\t\ty[y<0.5]=0\n",
        "\n",
        "\t\t# return the numpy array y which contains the predicted values\n",
        "\t\treturn y\n",
        "\n",
        "\tdef plot_loss(self):\n",
        "\t\tprint(\"Thetas:\",self.theta)\n",
        "\t\tprint(\"Training Loss:\",self.training_loss[-1])\n",
        "\t\tprint(\"Validation Loss:\",self.validation_loss[-1])\n",
        "\n",
        "\t\tplt.plot(self.training_loss,color=\"g\", label=\"Training Loss\")\n",
        "\t\tplt.plot(self.validation_loss,color=\"r\",label=\"Validation Loss\")\n",
        "\t\tplt.xlabel('Iteration')\n",
        "\t\tplt.ylabel('Loss')\n",
        "\t\tplt.legend()\n",
        "\t\t# ax = plt.gca()\n",
        "\t\t# ax.set_facecolor('white')\n",
        "\t\t# ax.spines['bottom'].set_color('black')\n",
        "\t\t# ax.spines['top'].set_color('black') \n",
        "\t\t# ax.spines['right'].set_color('black')\n",
        "\t\t# ax.spines['left'].set_color('black')\n",
        "\t\tplt.show()\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erIgoN4nvyyr",
        "colab_type": "text"
      },
      "source": [
        "## Dataset 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYa7lf2fv11j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessor = MyPreProcessor()\n",
        "X, y = preprocessor.pre_process(2)\n",
        "X_test=X[:X.shape[0]//10]\n",
        "y_test=y[:y.shape[0]//10]\n",
        "\n",
        "X_train=X[X.shape[0]//10:]\n",
        "y_train=y[y.shape[0]//10:]\n",
        "\n",
        "logistic = MyLogisticRegression()\n",
        "logistic.fit(X_train, y_train,X_test,y_test,epoch=10000,alpha=0.01,type=1)\n",
        "print(logistic.training_acc[-1],logistic.validation_acc[-1])\n",
        "logistic.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cz0N11MC6T3",
        "colab_type": "text"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qiJANxGC7yE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8a1a2f3-9624-4ea7-c1ae-b60b388fbfae"
      },
      "source": [
        "df=pd.read_csv('/content/data_banknote_authentication.txt',header=None)\n",
        "df.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x1440 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "660nb9IxETJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7c352b0c-7cfe-4098-9fa3-b474ab25bc75"
      },
      "source": [
        "df=pd.read_csv('/content/data_banknote_authentication.txt',header=None)\n",
        "df.corr()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.264026</td>\n",
              "      <td>-0.380850</td>\n",
              "      <td>0.276817</td>\n",
              "      <td>-0.724843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.264026</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.786895</td>\n",
              "      <td>-0.526321</td>\n",
              "      <td>-0.444688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.380850</td>\n",
              "      <td>-0.786895</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>0.155883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.276817</td>\n",
              "      <td>-0.526321</td>\n",
              "      <td>0.318841</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.023424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.724843</td>\n",
              "      <td>-0.444688</td>\n",
              "      <td>0.155883</td>\n",
              "      <td>-0.023424</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4\n",
              "0  1.000000  0.264026 -0.380850  0.276817 -0.724843\n",
              "1  0.264026  1.000000 -0.786895 -0.526321 -0.444688\n",
              "2 -0.380850 -0.786895  1.000000  0.318841  0.155883\n",
              "3  0.276817 -0.526321  0.318841  1.000000 -0.023424\n",
              "4 -0.724843 -0.444688  0.155883 -0.023424  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa9AxYh_cOMD",
        "colab_type": "text"
      },
      "source": [
        "## Sklearn Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oDRuzR-cRRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQhMTMPxcTy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f2e39074-ce84-4321-f8c6-3b3de278783a"
      },
      "source": [
        "preprocessor = MyPreProcessor()\n",
        "x, y = preprocessor.pre_process(2)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=4)\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(x_train,y_train)\n",
        "y_pred = logistic_regression.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Test:\",accuracy)\n",
        "y_pred1 = logistic_regression.predict(x_train)\n",
        "accuracy = metrics.accuracy_score(y_train, y_pred1)\n",
        "print(\"Accuracy Train:\",accuracy)\n",
        "print(\"Thetas:\",logistic_regression.coef_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Test: 0.9795918367346939\n",
            "Accuracy Train: 0.9825072886297376\n",
            "Thetas: [[-4.58128443 -4.68888037 -4.27457391  0.23536925]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOUVjO6MSZBi",
        "colab_type": "text"
      },
      "source": [
        "# Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1a1xWkZdRyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "32a81fd9-dd01-4a90-a80e-074ad05e5548"
      },
      "source": [
        "preprocessor = MyPreProcessor()\n",
        "X, y = preprocessor.pre_process(3)\n",
        "X=np.concatenate((np.ones((X.shape[0],1)),X),axis=1)\n",
        "X_trans=np.transpose(X)\n",
        "np.linalg.inv(X_trans.dot(X)).dot(X_trans).dot(y)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42424242],\n",
              "       [0.2746465 ],\n",
              "       [0.14256181]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdbZwPiFGwiK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "3f8b307d-02e5-4467-8623-aa233a182bba"
      },
      "source": [
        "Xtrain = np.array([[1, 2, 3], \n",
        "                   [4, 5, 6]])\n",
        "ytrain = np.array([1, 2])\n",
        "\n",
        "Xtest = np.array([[7, 8, 9]])\n",
        "ytest = np.array([3])\n",
        "\n",
        "print('Linear Regression')\n",
        "\n",
        "linear = MyLinearRegression()\n",
        "linear.fit(Xtrain, ytrain)\n",
        "\n",
        "ypred = linear.predict(Xtest)\n",
        "\n",
        "print('Predicted Values:', ypred)\n",
        "print('True Values:', ytest)\n",
        "\n",
        "print('Logistic Regression')\n",
        "\n",
        "logistic = MyLogisticRegression()\n",
        "logistic.fit(Xtrain, ytrain)\n",
        "\n",
        "ypred = logistic.predict(Xtest)\n",
        "\n",
        "print('Predicted Values:', ypred)\n",
        "print('True Values:', ytest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Regression\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "Predicted Values: [3.47084775]\n",
            "True Values: [3]\n",
            "Logistic Regression\n",
            "Predicted Values: [1.]\n",
            "True Values: [3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}