{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyYu+C9XZM0LqNxqquKnQp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itissandeep98/ML-Assignments/blob/master/ML_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5O3iEtAFqzd",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEo5gx2hZQKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9RJnOQAEAU3",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kS_U4I6EDez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyPreProcessor():\n",
        "    \"\"\"\n",
        "    My steps for pre-processing for the three datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def pre_process(self, dataset):\n",
        "        \"\"\"\n",
        "        Reading the file and preprocessing the input and output.\n",
        "        Note that you will encode any string value and/or remove empty entries in this function only.\n",
        "        Further any pre processing steps have to be performed in this function too. \n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        dataset : integer with acceptable values 0, 1, or 2\n",
        "        0 -> Abalone Dataset\n",
        "        1 -> VideoGame Dataset\n",
        "        2 -> BankNote Authentication Dataset\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        X : 2-dimensional numpy array of shape (n_samples, n_features)\n",
        "        y : 1-dimensional numpy array of shape (n_samples,)\n",
        "        \"\"\"     \n",
        "\n",
        "        if dataset == 0:\n",
        "            df=pd.read_csv('/content/Dataset.data',delim_whitespace=True,header=None)\n",
        "            df.sample(frac=1)\n",
        "            df[0].replace('M',1,inplace=True)\n",
        "            df[0].replace('F',2,inplace=True)\n",
        "            df[0].replace('I',3,inplace=True)\n",
        "            \n",
        "            data=df.to_numpy()\n",
        "            X=data[:,:-1]\n",
        "            y=data[:,-1]\n",
        "\n",
        "        elif dataset == 1:\n",
        "            df=pd.read_csv('/content/VideoGameDataset.csv')\n",
        "            df=df[['Critic_Score','Global_Sales','User_Score']]\n",
        "            df=df.sample(frac=1)\n",
        "\n",
        "            df['Critic_Score'].fillna(df['Critic_Score'].median(), inplace=True)\n",
        "            df['User_Score'].replace(to_replace = 'tbd', value = np.nan,inplace=True)\n",
        "            df['User_Score']=df['User_Score'].astype(np.float)\n",
        "            df['User_Score'].fillna(df['User_Score'].median(), inplace=True)\n",
        "\n",
        "            data=df.to_numpy()\n",
        "            X=data[:,:-1]\n",
        "            y=data[:,-1]\n",
        "\n",
        "        elif dataset == 2:\n",
        "            # Implement for the banknote authentication dataset\n",
        "            pass\n",
        "\n",
        "        return X, y\n"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSTeIMNDSrEl",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gofY4sQaGeYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLinearRegression():\n",
        "  \"\"\"\n",
        "\tMy implementation of Linear Regression.\n",
        "\t\"\"\"\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def cross_validation(self,X,y,epoch=1000,alpha=0.01,k=10,lossfunc=1):\n",
        "    \"\"\"\n",
        "    performs k fold cross validation on the given dataset\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features) \n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,)\n",
        "\n",
        "    k : Number of folds the data needs to be splitted into\n",
        "\n",
        "    epoch : Number of times gradient descent has to run\n",
        "\n",
        "    alpha : Learning rate of gradient descent\n",
        "\n",
        "    lossfunc: determines which loss function to call\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    derv : derivative of cost at the value theta\n",
        "    err  : Error/cost in prediction at the value theta\n",
        "    \"\"\"\n",
        "    m=X.shape[0] # number of samples\n",
        "\n",
        "    split_start=0 # initial split's first index\n",
        "    split_end=m//k # initial split's last index\n",
        "\n",
        "    theta_list=[0]*k  # initialized theta\n",
        "    training_loss_list=[0]*k  # initialized list to store all the training loss from every fold\n",
        "    validation_loss_list=[0]*k # initialized list to store all the validation loss from every fold\n",
        "\n",
        "    error_min=float(\"inf\")\n",
        "    idx=0\n",
        "\n",
        "    for i in range(k):\n",
        "\n",
        "      # Extracting X and y for train and test set\n",
        "      X_train=np.concatenate((X[:split_start],X[split_end:]),axis=0)\n",
        "      y_train=np.concatenate((y[:split_start],y[split_end:]),axis=0)\n",
        "\n",
        "      X_test=X[split_start:split_end]\n",
        "      y_test=y[split_start:split_end]\n",
        "\n",
        "      self.fit(X_train,y_train,X_test,y_test,epoch,alpha,lossfunc) # calculating model parameters by running the gradient descent\n",
        "\n",
        "      # storing the results of current fold in the array\n",
        "      theta_list[i]=self.theta\n",
        "      training_loss_list[i]=self.training_loss\n",
        "      validation_loss_list[i]=self.validation_loss\n",
        "\n",
        "      split_start=split_end # updating slice parameters\n",
        "      split_end+=m//k\n",
        "\n",
        "      error=training_loss_list[i][-1]\n",
        "\n",
        "\n",
        "      # if the error in this fold is minimum of all errors seen upto now then update it and store the fold number\n",
        "      if(error<error_min):\n",
        "        idx=i\n",
        "        error_min=error\n",
        "    \n",
        "    # final storing the values associated with minimum error \n",
        "    self.theta=theta_list[idx]\n",
        "    self.training_loss=training_loss_list[idx]\n",
        "    self.validation_loss=validation_loss_list[idx]\n",
        "\n",
        "  def MSE(self,X,y,theta):\n",
        "    \"\"\"\n",
        "    finding Mean Squared Error based on current model parameters\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features)\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,)\n",
        "\n",
        "    theta : Value of theta at which derivative of cost has to be found\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    derv : derivative of cost at the value theta\n",
        "    err  : Error/cost in prediction at the value theta\n",
        "    \"\"\"\n",
        "    m=len(y)\n",
        "\n",
        "    X_trans=np.transpose(X)                                           # Transpose of vector X\n",
        "    err=X.dot(theta)-y\n",
        "    derv =(1/m)*(X_trans.dot(err))                         # Calculates X` * ( X*theta - y )\n",
        "    \n",
        "    return derv,sum(err**2)/m    \n",
        " \n",
        "  def MAE(self,X,y,theta):\n",
        "    \"\"\"\n",
        "    finding Mean Average Error based on current model parameters\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features)\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,)\n",
        "\n",
        "    theta : Value of theta at which derivative of cost has to be found\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    derv : derivative of cost at the value theta\n",
        "    err  : Error/cost in prediction at the value theta\n",
        "    \"\"\"\n",
        "    m=len(y)\n",
        "    err=(1/m)*(X.dot(theta)-y)\n",
        "    X_trans=X.T\n",
        "   \n",
        "    grad=(1/m)*(X_trans.dot(abs(err)/err))\n",
        "    \n",
        "    return grad,sum(abs(err))\n",
        "\n",
        "  def RMSE(self,X,y,theta):\n",
        "    \"\"\"\n",
        "    finding Root Mean Squared Error based on current model parameters\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features)\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,) \n",
        "\n",
        "    theta : Value of theta at which derivative of cost has to be found\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    derv : derivative of cost at the value theta\n",
        "    err  : Error/cost in prediction at the value theta\n",
        "    \"\"\"\n",
        "    X_trans=X.T                                               # Transpose of vector X\n",
        "    y_hat=X.dot(theta)-y\n",
        "    m=len(y)\n",
        "   \n",
        "    err=((1/m)*np.sum((y_hat)**2))**0.5\n",
        "    derv =(1/m)*(X_trans.dot(y_hat))/err         \n",
        "    \n",
        "    return derv,err\n",
        "\n",
        "\n",
        "  def gradient_descent(self,X,y,X_test,y_test,epochs,alpha,lossfunc):\n",
        "    \"\"\"\n",
        "    Finding theta using the gradient descent method\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "    X_test : 2-dimensional numpy array of shape (n_samples, n_features) which acts as Testing data.\n",
        "\n",
        "    y_test : 1-dimensional numpy array of shape (n_samples,) which acts as Testing labels.\n",
        "\n",
        "    epochs : Number of times gradient descent has to run\n",
        "\n",
        "    alpha : Learning rate of gradient descent\n",
        "\n",
        "    lossfunc: determines which loss function to call\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    theta : Calculated value of theta on given test set (X,y) with learning rate alpha \n",
        "\n",
        "    training_loss: Calculated training loss at every theta\n",
        "\n",
        "    tvalidation_loss: Calculated validation loss at every theta\n",
        "    \"\"\"\n",
        "   \n",
        "    theta= np.zeros((X.shape[1],))                      # created a column vector theta of length equal to number of features in X with all the initial values 0\n",
        "    \n",
        "    training_loss=np.array([])  # initializing array to store training loss at every value of theta\n",
        "    validation_loss= np.array([]) # initializing array to store validation loss at every value of theta\n",
        "\n",
        "    # print(\"-*\"*20)\n",
        "\n",
        "    for i in range(epochs): \n",
        "      if(lossfunc==1): \n",
        "        derv,train_loss=self.RMSE(X,y,theta)   \n",
        "      elif(lossfunc==2):   \n",
        "        derv,train_loss=self.MAE(X,y,theta)\n",
        "      else:\n",
        "        derv,train_loss=self.MSE(X,y,theta)\n",
        "      training_loss=np.append(training_loss,train_loss)\n",
        "\n",
        "      # if(i%400==0):\n",
        "      #   print(\"Iteration:\",i,\"Training error:\",train_loss)\n",
        "\n",
        "      if(X_test is not None): # calculate validation loss only if test set is provided\n",
        "        if(lossfunc==1):\n",
        "          derv_val,val_loss=self.RMSE(X_test,y_test,theta)   \n",
        "        elif(lossfunc==2):   \n",
        "          derv_val,val_loss=self.MAE(X_test,y_test,theta)\n",
        "        else:\n",
        "          derv_val,val_loss=self.MSE(X_test,y_test,theta)\n",
        "      \n",
        "        validation_loss=np.append(validation_loss,val_loss)\n",
        "        \n",
        "      theta=theta-alpha*derv\n",
        "      \n",
        "  \n",
        "    return theta,training_loss,validation_loss\n",
        "\n",
        "  def fit(self, X, y,X_test=None,y_test=None,epoch=400,alpha=0.01,lossfunc=1):\n",
        "    \"\"\"\n",
        "    Fitting (training) the linear model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "    y : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    self : an instance of self\n",
        "    \"\"\"\n",
        "\n",
        "    X=np.concatenate((np.ones((X.shape[0],1)),X),axis=1) # Adding a bias variable i.e columns of 1 to data\n",
        "\n",
        "    if(X_test is not None): # if validation set is provided then add a bias variable i.e columns of 1 to data\n",
        "      X_test=np.concatenate((np.ones((X_test.shape[0],1)),X_test),axis=1)\n",
        "   \n",
        "    X_trans=np.transpose(X)\n",
        "    if(lossfunc==4):\n",
        "      try:\n",
        "        self.theta = np.linalg.inv(X_trans.dot(X)).dot(X_trans).dot(y)  # using the normal eqn, theta = inv(X`*X)*X`*y\n",
        "      except:\n",
        "        self.theta,self.training_loss,self.validation_loss = self.gradient_descent(X,y,X_test,y_test,epoch,alpha,lossfunc=1) # using the gradient descent method with RMSE loss function if the given data is non invertible\n",
        "    else: \n",
        "      self.theta,self.training_loss,self.validation_loss = self.gradient_descent(X,y,X_test,y_test,epoch,alpha,lossfunc) # using the gradient descent method with given number of epochs and learning rate\n",
        "      \n",
        "\n",
        "    # fit function has to return an instance of itself or else it won't work with test.py\n",
        "    return self\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Predicting values using the trained linear model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    y : 1-dimensional numpy array of shape (n_samples,) which contains the predicted values.\n",
        "    \"\"\"\n",
        "    X=np.concatenate((np.ones((X.shape[0],1)),X),axis=1)\n",
        "    y=np.dot(X,self.theta)\n",
        "    # return the numpy array y which contains the predicted values\n",
        "    return y\n",
        "\n",
        "  def plot_loss(self):\n",
        "    print(\"Thetas:\",self.theta)\n",
        "    print(\"Training Loss:\",self.training_loss[-1])\n",
        "    print(\"Validation Loss:\",self.validation_loss[-1])\n",
        "    \n",
        "    x=np.arange(self.training_loss.shape[0])\n",
        "    plt.plot(x,self.training_loss,color=\"g\", label=\"Training Loss\")\n",
        "    plt.plot(x,self.validation_loss,color=\"r\",label=\"Validation Loss\")\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E68z99ULqRBt",
        "colab_type": "text"
      },
      "source": [
        "## Dataset1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FrZ20anXvGL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "185f1621-ec4c-43aa-bb2e-81e14811907b"
      },
      "source": [
        "preprocessor = MyPreProcessor()\n",
        "X, y = preprocessor.pre_process(0)\n",
        "\n",
        "linear = MyLinearRegression()\n",
        "linear.cross_validation(X,y,lossfunc=1)\n",
        "linear.plot_loss()\n",
        "\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thetas: [2.5769917  1.02920677 1.62578726 1.29796717 0.47071786 3.09257129\n",
            " 1.15003946 0.65734139 1.01654006]\n",
            "Training Loss: 2.703392422960864\n",
            "Validation Loss: 4.676936786313666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HHOIS1Wb9tpj"
      },
      "source": [
        "## Dataset2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpSzdHFk9tpz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "696a6a3c-dfe3-46be-b915-4851d0fcb32c"
      },
      "source": [
        "preprocessor = MyPreProcessor()\n",
        "X, y = preprocessor.pre_process(1)\n",
        "\n",
        "linear = MyLinearRegression()\n",
        "linear.cross_validation(X,y,epoch=40,alpha=0.0001,lossfunc=1)\n",
        "linear.plot_loss()\n",
        "\n",
        "\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thetas: [0.00165914 0.1036596  0.00030808]\n",
            "Training Loss: 1.0408345429164667\n",
            "Validation Loss: 1.0789948404798702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3zO9f/H8cdrM9bM2SimTEU5bgydm76dfhJfotJRfaN8S6VvpTMdHPpSyjclpbNIKp0oJUX5fmOOEYpMjTCLGTZ2eP/+2GWhmZld+1y7ruf9drvadfpcn+c+a0+fva/P9f6Ycw4REQk+YV4HEBER/1DBi4gEKRW8iEiQUsGLiAQpFbyISJCq5HWA/dWtW9c1btzY6xgiIhXGwoULtzrnYop6LKAKvnHjxiQnJ3sdQ0SkwjCz9Yd6TEM0IiJBSgUvIhKkVPAiIkEqoMbgRaR85OTkkJqaSnZ2ttdRpIQiIyOJjY0lIiKixMuo4EVCUGpqKtWqVaNx48aYmddx5DCcc6Snp5OamkpcXFyJl9MQjUgIys7Opk6dOir3CsLMqFOnzhH/xaWCFwlRKveKpTQ/rwpf8Nm52YyaN4q56+d6HUVEJKBU+IInM5Nj/zWYGSP7obntRSqG9PR04uPjiY+P59hjj6Vhw4aFt/fu3VvsssnJydx+++2HXccZZ5xRJlm//vprunTpUiavVd4q/JuskdVr03lzdRKmrGLmgBlc1Kyz15FE5DDq1KnDkiVLABgyZAjR0dHcfffdhY/n5uZSqVLR9ZSYmEhiYuJh1zFv3ryyCVuBVfw9+PBwqo0YTYs0+HbkbdqLF6mg+vTpwy233ELHjh259957mT9/PqeffjoJCQmcccYZrF69Gjhwj3rIkCHceOONJCUl0aRJE8aMGVP4etHR0YXPT0pKomfPnpxyyilcffXVhT0xffp0TjnlFNq1a8ftt99+RHvqkyZNolWrVrRs2ZJBgwYBkJeXR58+fWjZsiWtWrVi9OjRAIwZM4bmzZvTunVrrrzyyqPfWCVU4ffgASJ6Xk5603u57oN1fDJwGpe26O51JJEK487P7mTJpiVl+prxx8bzzMXPHPFyqampzJs3j/DwcHbs2MHcuXOpVKkSX375JQ888ADvvffeX5ZZtWoVs2fPJjMzk2bNmtG/f/+/HCu+ePFiVqxYQYMGDTjzzDP57rvvSExM5Oabb2bOnDnExcXRu3fvEufcuHEjgwYNYuHChdSqVYsLL7yQadOm0ahRIzZs2MDy5csB2L59OwAjRoxg3bp1VKlSpfC+8lDx9+ABwsKo+e8xnPwHJD95O/ku3+tEIlIKvXr1Ijw8HICMjAx69epFy5YtGThwICtWrChymUsuuYQqVapQt25d6tWrx+bNm//ynA4dOhAbG0tYWBjx8fGkpKSwatUqmjRpUnhc+ZEU/IIFC0hKSiImJoZKlSpx9dVXM2fOHJo0acIvv/zCgAED+Oyzz6hevToArVu35uqrr+att9465NCTPwTFHjxAeNdubG15Ijd+tJYPlkzmsoSrvI4kUiGUZk/bX6pWrVp4/eGHH6ZTp0588MEHpKSkkJSUVOQyVapUKbweHh5Obm5uqZ5TFmrVqsXSpUv5/PPPGTduHFOmTOGVV17h008/Zc6cOXz88ccMHTqUH374oVyKPjj24AHMqDXyP5yQAStG3EVefp7XiUTkKGRkZNCwYUMAXnvttTJ//WbNmvHLL7+QkpICwDvvvFPiZTt06MA333zD1q1bycvLY9KkSZx77rls3bqV/Px8LrvsMp544gkWLVpEfn4+v/32G506deLJJ58kIyODnTt3lvn3U5TgKXgg/KKLSWt7CjdN38yU5Ne9jiMiR+Hee+/l/vvvJyEhwS973McccwzPP/88F198Me3ataNatWrUqFGjyOfOmjWL2NjYwktKSgojRoygU6dOtGnThnbt2tGtWzc2bNhAUlIS8fHxXHPNNQwfPpy8vDyuueYaWrVqRUJCArfffjs1a9Ys8++nKBZIR50kJia6oz3hR/7XswnrdB5Du9dl0NTfqRQWNKNQImVm5cqVnHrqqV7H8NzOnTuJjo7GOcett97KySefzMCBA72OdUhF/dzMbKFzrsjjRoNqDx4gLKkTaWe0oe/nW3n7v+O9jiMiAeyll14iPj6eFi1akJGRwc033+x1pDLlt4I3s2ZmtmS/yw4zu9Nf69tf3VEvUG83bBr+IHvziv9UnIiEroEDB7JkyRJ+/PFHJk6cSFRUlNeRypTfCt45t9o5F++ciwfaAbuBD/y1vv3Z6aezJakDN83azptzniuPVYqIBJzyGqL5G7DWOXfIk8OWtZhRz1M7G7aPGExWTlZ5rVZEJGCUV8FfCUwq6gEz62dmyWaWnJaWVmYrtHbt2HLR2fT9eievf/V0mb2uiEhF4feCN7PKQFfg3aIed86Nd84lOucSY2JiynTd9UY9T3QO7H1yGLv27irT1xYRCXTlsQf/f8Ai59xfPz/sby1bkn7p+fzj29288tnwcl+9iBStU6dOfP755wfc98wzz9C/f/9DLpOUlMS+w6g7d+5c5JwuQ4YMYdSoUcWue9q0afz444+Ftx955BG+/PLLI4lfpECcVrg8Cr43hxieKQ8xI8cSmQuVRo5ix54dXsUQkf307t2byZMnH3Df5MmTSzwfzPTp00v9YaGDC/6xxx7j/PPPL9VrBTq/FryZVQUuAN7353qK1bQp2y6/lBv+u4cJHz3qWQwR+VPPnj359NNPC0/ukZKSwsaNGzn77LPp378/iYmJtGjRgsGDBxe5fOPGjdm6dSsAQ4cOpWnTppx11lmFUwpDwTHu7du3p02bNlx22WXs3r2befPm8dFHH3HPPfcQHx/P2rVr6dOnD1OnTgUKPrGakJBAq1atuPHGG9mzZ0/h+gYPHkzbtm1p1aoVq1atKvH36uW0wn79mKdzbhdQx5/rKIm6I8aQM/UTqj/1H/7o8iC1j6ntdSSRwHHnnbCkbKcLJj4enjn0JGa1a9emQ4cOzJgxg27dujF58mQuv/xyzIyhQ4dSu3Zt8vLy+Nvf/sayZcto3bp1ka+zcOFCJk+ezJIlS8jNzaVt27a0a9cOgB49etC3b18AHnroISZMmMCAAQPo2rUrXbp0oWfPnge8VnZ2Nn369GHWrFk0bdqU6667jhdeeIE77yz4+E7dunVZtGgRzz//PKNGjeLll18+7GbwelrhoPska5EaN2bHNb24bkEOr7z3sNdpRIQDh2n2H56ZMmUKbdu2JSEhgRUrVhwwnHKwuXPn0r17d6KioqhevTpdu3YtfGz58uWcffbZtGrViokTJx5yuuF9Vq9eTVxcHE2bNgXg+uuvZ86cOYWP9+jRA4B27doVTlB2OF5PKxwyE7XUGfo0e9+eSv3R49nSfTD1qtbzOpJIYChmT9ufunXrxsCBA1m0aBG7d++mXbt2rFu3jlGjRrFgwQJq1apFnz59yM7OLtXr9+nTh2nTptGmTRtee+01vv7666PKu2/K4bKYbri8phUOjT14gIYN2fmPa7lqcS6vTBrkdRqRkBcdHU2nTp248cYbC/fed+zYQdWqValRowabN29mxowZxb7GOeecw7Rp08jKyiIzM5OPP/648LHMzEyOO+44cnJymDhxYuH91apVIzMz8y+v1axZM1JSUlizZg0Ab775Jueee+5RfY9eTyscMnvwALUf/Td7Xp1IkzFvsPGKoTSo1sDrSCIhrXfv3nTv3r1wqKZNmzYkJCRwyimn0KhRI84888xil2/bti1XXHEFbdq0oV69erRv377wsccff5yOHTsSExNDx44dC0v9yiuvpG/fvowZM6bwzVWAyMhIXn31VXr16kVubi7t27fnlltuOaLvZ9+0wvu8++67hdMKO+e45JJL6NatG0uXLuWGG24gP7/g7HP7TyuckZGBc65MphUOuumCD2fbXf+k1ugXGPbcFTxw6+TDLyAShDRdcMUU8tMFH06th4eyu2plWoydwvrt5TY1johIuQu5gqdWLXLuGEC3lY43J9zhdRoREb8JvYIHagx6hJ3VI0kc9yFr/ljjdRwRTwTS8KwcXml+XiFZ8FSvTv4993DxGpg87jav04iUu8jISNLT01XyFYRzjvT0dCIjI49ouZB7k7XQ7t1kxsawsPpu6s1fTvN6LcpnvSIBICcnh9TU1FIfYy7lLzIyktjYWCIiIg64v7g3WUPqMMkDREVhDz5E0t0P8Nhz/+SRx77xOpFIuYmIiCAuLs7rGOJnoTlE4xN9211sr1edC16dw5LfF3sdR0SkTIV0wVOlCpUHP8bpqfDR00f2gQYRkUAX2gUPRPX9J380rM2lb83n+1//63UcEZEyE/IFT0QEUU88ScImmDlSe/EiEjxU8EDktTewNa4+PScv45u1X3kdR0SkTKjgAcLDqTZ8NKduhbnDb9GxwSISFFTwPlUuv5K0Zo246r2f+WLlp17HERE5air4fcyoOfI/NNkOycNu0168iFR4Kvj9RHTpyuY2J3HdR+v5eNm7XscRETkqKvj9mVH3qReIzYRVj99Bvsv3OpGISKmp4A8S/rfz2dSxJX1mbOL9BW94HUdEpNT8WvBmVtPMpprZKjNbaWan+3N9ZaXe6Beptxt+ffxucvOP7uS6IiJe8fce/LPAZ865U4A2wEo/r69MhJ1+BpuSErnhy3Te+fZFr+OIiJSK3wrezGoA5wATAJxze51z2/21vrJW/+nx1MqG9CceZG/eXq/jiIgcMX/uwccBacCrZrbYzF42s6oHP8nM+plZspklp6Wl+THOkbGEBH7vfA43fJPBxFnPeB1HROSI+bPgKwFtgReccwnALuC+g5/knBvvnEt0ziXGxMT4Mc6RO3bUOKJyYM+wx8jKyfI6jojIEfFnwacCqc657323p1JQ+BWGnXoqaT0u4vrvdvHG9OFexxEROSJ+K3jn3CbgNzNr5rvrb8CP/lqfvxw78gUqOaPyiJFk7sn0Oo6ISIn5+yiaAcBEM1sGxAPD/Ly+shcXxx9X9+Ca+dm89v4jXqcRESkxvxa8c26Jb3y9tXPu7865bf5cn7/UHz6G/PAw6owcyx9Zf3gdR0SkRPRJ1pJo0IAdN13LlYtzeP3tQV6nEREpERV8CcU8NorsYyrRePSrbNq5yes4IiKHpYIvqbp1ybr1ZrqvyOOt1+7yOo2IyGGp4I9AnYeGsiu6Mi3HTOa3jN+8jiMiUiwV/JGoUYO9d9/FxT87Jo271es0IiLFUsEfoVr3PExGrShOe+Fj1qT/7HUcEZFDUsEfqago7MEHOWc9TH32Fq/TiIgckgq+FKrf9i+21avO3yZ8xfLNP3gdR0SkSCr40qhShYhHn6D9Rvj03329TiMiUiQVfClF39SfrY3qcMmb35P82/eHX0BEpJyp4EurUiWiho2kZRp8NUx78SISeFTwRyHqquvZctJxXPbOD8xd85XXcUREDqCCPxphYVQf9RwnboP/Pd4P55zXiURECqngj1Jk1+783roJV32wlpnLP/Q6johIIRX80TKj7ugXaZgJKx69lXyX73UiERFABV8mIs47n42nt+S66Rv5aMFbXscREQFU8GWm/rMTqJsFqUPuIi8/z+s4IiIq+LIS3r4DqRecxvWz0nn3mxe8jiMiooIvSw1Hv0xUDux47EH25O7xOo6IhDgVfBmyFi3Y9PfzuW7uDibNGOl1HBEJcSr4MtbgqfGEY4QNG8bunN1exxGREKaCL2MWF0faNd3pPT+Lt94f4nUcEQlhfi14M0sxsx/MbImZJftzXYGkwYix5FUKo9aIZ8nIzvA6joiEqPLYg+/knIt3ziWWw7oCw7HHsr3fdVy2ZC9vvXWv12lEJERpiMZPjn3sabKiImj89ATSdqV5HUdEQpC/C94BM81soZn1K+oJZtbPzJLNLDktLYiKsFYtdt35Ty5ZmcfbL93udRoRCUHmzxkQzayhc26DmdUDvgAGOOfmHOr5iYmJLjk5iIbqd+4kIzaGxbX3cOKiFBrVPN7rRCISZMxs4aGGwP26B++c2+D7ugX4AOjgz/UFnOho8h64j6R1jnfH3Ox1GhEJMX4reDOrambV9l0HLgSW+2t9gar2HfeRXq8a57z4GT9tXe11HBEJIf7cg68PfGtmS4H5wKfOuc/8uL7AVKUKEU8MI3EjfDL8Bq/TiEgI8esY/JEKujH4ffLy2HzScWzLTGP34u9p2yi0RqpExH88G4MXn/Bwop8czSnp8M1j//A6jYiECBV8Oana6yo2Nj+enlOWM3f1F17HEZEQoIIvL2bUeeZFGu2AxY/oBN0i4n8q+HJU5YKL+a3jqVz1cQozF0/1Oo6IBDkVfDk77tlXqJsFKQ8P0Am6RcSvVPDlrFLH0/j1gg5c9eVmps15yes4IhLEVPAeiH32VaJyIGPwIHLycryOIyJBSgXvgbBTm7Phsgu46tsMpkzXqf1ExD9U8B5p9NTLYEb440+QlZPldRwRCUIqeI/Y8ceTdn1PeiVnMXHKQ17HEZEgVKKC900cFua73tTMuppZhH+jBb/Y4WPZUyWc+sP/w/bs7V7HEZEgU9I9+DlApJk1BGYC1wKv+StUyIiJIWNAXy5dkcOkl+7wOo2IBJmSFrw553YDPYDnnXO9gBb+ixU6jntkJBk1Imnx9Fv8vmOj13FEJIiUuODN7HTgauBT333h/okUYqKj2Xv/vZyTks97o/t6nUZEgkhJC/5O4H7gA+fcCjNrAsz2X6zQEjPwQdKOrc7Z46azZutPXscRkSBRooJ3zn3jnOvqnHvS92brVuecziRdVipXJmLocNpsgs8ev97rNCISJEp6FM3bZlbdd+q95cCPZnaPf6OFlpp9bmHjSfXp/Mb/WLJ+vtdxRCQIlHSIprlzbgfwd2AGEEfBkTRSVsLCqPHUWJpsh+8e0V68iBy9khZ8hO+4978DHznncgBNaF7Gql7ag18TTqTne6uYs3y613FEpIIracG/CKQAVYE5ZnYCsMNfoUKWGfX+M4H6u2DVgzopiIgcnZK+yTrGOdfQOdfZFVgPdPJztpAUeea5rDuvLb0/28D0ea97HUdEKrCSvslaw8yeNrNk3+UpCvbmxQ8a/ed1onIg/aG7yM3P9TqOiFRQJR2ieQXIBC73XXYAr5ZkQTMLN7PFZvZJ6SKGnkrNW/LrZedzxdxtfDBjtNdxRKSCKmnBn+icG+yc+8V3eRRoUsJl7wBWli5e6Go8+lVcmBE2ZAjZudlexxGRCqikBZ9lZmftu2FmZwKHncTczGKBS4CXSxcvdFlsLJtvuILuybt55+0HvY4jIhVQSQv+FmCsmaWYWQrwHHBzCZZ7BrgXOOTZpc2s376x/bS0tBLGCQ0njHieXVUjaDBsDNuytnkdR0QqmJIeRbPUOdcGaA20ds4lAOcVt4yZdQG2OOcWHua1xzvnEp1ziTExMSXNHRpq1SLzX7dxwepcpj73T6/TiEgFc0RndHLO7fB9ohXgrsM8/Uygq2+PfzJwnpm9deQRQ1uD+4extW5V2j7zDr9tW+91HBGpQI7mlH1W3IPOufudc7HOucbAlcBXzrlrjmJ9oSkyEh5/jHYbHdOH9vE6jYhUIEdT8PqYZTmp2/cONsbV5fxXvubH1CVexxGRCqLYgjezTDPbUcQlE2hQ0pU45752znU56rShKjyc6NHPc+I2+PZB/REkIiVTbME756o556oXcanmnKtUXiEFqnftSUq7E+nx7grm/TDD6zgiUgEczRCNlCczjh37OnWz4Kf7btJEZCJyWCr4CiSy45msvagDl8/cyIxv9NkxESmeCr6COWHsW0Q42PnA3ZqITESKpYKvYCqdeDK/XnMpl/1vB+9NfdzrOCISwFTwFVCTkRPIigynxmNPsmvvLq/jiEiAUsFXQBYTQ/qAm7h4xR6mvniH13FEJECp4CuoEwY/TXrtSJqPfJUtOzd7HUdEApAKvqKKimLvIw/T/rd8Ph56nddpRCQAqeArsONuG0RqXB06vTiTnzb84HUcEQkwKviKLDyc6GdfoMk2+Pa+3l6nEZEAo4Kv4Gpe2ou1HZvSfeoK5i352Os4IhJAVPBBoOELE6m+B9bf3Zd8d8iTZ4lIiFHBB4HIhETWdj+Xy2ZvZvqMMV7HEZEAoYIPEic99za5EWGE3f8g2bnZXscRkQCggg8SYcc14Pf+19F52W4+eOlfXscRkQCggg8iJw4dy9ZaVTh5+Iuk79rqdRwR8ZgKPphERbFnyMMk/pbHp4/rw08ioU4FH2Qa3nofv8bV4ZwXZ/DLxh+9jiMiHlLBB5vwcKo++zyNt8N3g/ThJ5FQpoIPQnUuvZyfTjuZS99dxoKlOn+rSKhSwQep2HFvE50DKXfdqPO3ioQovxW8mUWa2XwzW2pmK8zsUX+tS/4qqk0ia3ok0X32JqZ/OMrrOCLiAX/uwe8BznPOtQHigYvN7DQ/rk8O0nTsZHYfE07V+x5ht878JBJy/FbwrsBO380I30VjBeUorF590v7Vn6TV2Xz49M1exxGRcmb+HJ81s3BgIXASMNY5N6iI5/QD+gEcf/zx7davX++3PCEpJ4fUuDpkZe/kmFVriK3bxOtEIlKGzGyhcy6xqMf8+iarcy7PORcPxAIdzKxlEc8Z75xLdM4lxsTE+DNOaIqIIGL0GE5Od8y5+3Kv04hIOSqXo2icc9uB2cDF5bE+OVD9Xn1Y3eFELpm8kIVLdNikSKjw51E0MWZW03f9GOACYJW/1ifFa/jyFKJy4Lc7+uiwSZEQ4c89+OOA2Wa2DFgAfOGc+8SP65NiRLdqy+reF9J1zhZmTB3udRwRKQd+fZP1SCUmJrrk5GSvYwSt/G1/kHF8fVbXC6P1yj+IqlzV60gicpQ8e5NVAktYrdpsvf8OTvtlL58Mv8HrOCLiZyr4EHPyoCdJOaEGHZ+ZSurmn72OIyJ+pIIPNeHhRD43jhO2O+YN7OV1GhHxIxV8CDq2y5UsP7sZl0xdysIFH3kdR0T8RAUfouJemkq4g7TbbiAvP8/rOCLiByr4EFW1WUt+vqkHF8//g+kv3u11HBHxAxV8CGv51JtsiImk2eAxbN2+0es4IlLGVPAhzKKiyH12NE3T8vnm9m5exxGRMqaCD3En9L6FH848mf+blMzi/37gdRwRKUMqeCHutQ9xYUbGLXrDVSSYqOCF6JNOZc1tV5G0LIPPnrnN6zgiUkZU8AJA6+GvkNKgKi2fGM+WtBSv44hIGVDBCwBWuTL2wgucsC2f72/VG64iwUAFL4VO6Hotiy5oyUXvLWPR7ElexxGRo6SClwM0m/AhWVWMvf37kZuX43UcETkKKng5QNVGTfjlnps4bfVOvhje1+s4InIUVPDyF/EPP89PcdVJ+PcbbN7wk9dxRKSUVPDyF1apEpHjX6XeTsfSPv/ndRwRKSUVvBTp+PN7sOCKs7nwy1+YM+ERr+OISCmo4OWQ2r38KSn1qxB391DSN63zOo6IHCEVvBxSparVyJvwMg0y8ll63YVexxGRI6SCl2KdeMk1fH/5GZz3xRr+++rjXscRkSPgt4I3s0ZmNtvMfjSzFWZ2h7/WJf6V+PJ01tWvQqO7HmX7ll+9jiMiJeTPPfhc4F/OuebAacCtZtbcj+sTP6kcXYM9L43juIw8llyroRqRisJvBe+c+905t8h3PRNYCTT01/rEv065tA/f9epI0szVJL823Os4IlIC5pzz/0rMGgNzgJbOuR0HPdYP6Adw/PHHt1u/fr3f80jpZO/czoaT6hO5J49qP6VQPSbW60giIc/MFjrnEot6zO9vsppZNPAecOfB5Q7gnBvvnEt0ziXGxMT4O44chcjommSNH8uxGXks1VCNSMDza8GbWQQF5T7ROfe+P9cl5aNl15uY0zORsz9fyZI3/u11HBEphj+PojFgArDSOfe0v9Yj5a/jhM9ZWz+Cenc8wM4tqV7HEZFD8Oce/JnAtcB5ZrbEd+nsx/VJOYmqVpsdL/6HmB15rL7kNFyezuMqEoj8eRTNt845c861ds7F+y7T/bU+KV8J3W7mqwFdaJe8gfm3/t3rOCJSBH2SVUrtgqenMfvMBrQf/wmr33rW6zgichAVvJRaWFg4bT78ntXHRVD/5rvY9uMiryOJyH5U8HJUateJJffdKbj8fNI7dyJ/9y6vI4mIjwpejlqrM/7OvGH9OWn9Dn647Gwohw/PicjhqeClTHS+cyzv92pFm88Ws2roQK/jiAgqeCkjZsaFb3zLnObRNBnyLFtmfeR1JJGQp4KXMhMdWZ36H8xkQ3WDXr3I+X2D15FEQpoKXspUs6ans3r8MKpl7mX9RadBVpbXkURClgpeytzFPe9jysALafJDKilntIDMTK8jiYQkFbz4xTUjpvPinWcRu3Qdv53WHLZt8zqSSMhRwYtfhIeF0++pr3l+UCfqrU7l9w7NcVu2eB1LJKSo4MVvwsPCuW3Yl4x96EJqpGwirX1zXKpmnxQpLyp48aswC+POwTMY+1gXIjel80f7lrhffvE6lkhIUMGL34VZGP+670OeH94D255BRsc2uFWrvI4lEvRU8FIuwiyMQQOnMm7UFezJ2snO09vhFi/2OpZIUFPBS7kxM+7/5yReHn0t2/N3k9shkT133QEZGV5HEwlKKngpV2bGAze9zpsvD+CtlvlEPDOG7LhGuHHjIDfX63giQUUFL+XOzHig1xhafbqAPg80Z361TKx/f7JbN4dZs7yOJxI0VPDimcQGibz2+A+sfu9F+lwTzcZNP8P555PTpTP89JPX8UQqPHMBNHd3YmKiS05O9jqGeCB9dzqPzLiXauNe4cG5RtW8MKxrN6xTJ0hKgubNIUz7IyIHM7OFzrnEIh9TwUsgmb9hPg9N6sul7y6j+5pKxP5RMC6fX7cOYecmFZS9Cl+kkApeKpS8/DzeXPYm7698nzWLvqTDz1l0Wm9c9Gtljv1jDwCuTh0sLg5iYv681K375/U6dSAyEiIiCi6VKx/4tVIlMCv4R8Ls0JdDKe6xAPqdkgokIqJUi3lS8Gb2CtAF2OKca1mSZVTwcrC9eXv5X+r/mLl2JjPXzlyTy4UAAAe1SURBVCRtxQLOTYHzNkRwYtYx1Ntt1NqVR/Ude6icneN1XJHSqV8fNm0q1aJeFfw5wE7gDRW8lJX03enMWjeLr9Z9xa8Zv7Jp5yY27dzE5l2bqbInn5jdELMLamdBlTyIyIPKeRCRX/D1GBdOlKtEFSoRhhHujDAgDDvgUrB/XsR/Dcz9eXufv+7QF7OHLxWTH3+kYVWrMWDS2lItW1zBVzqqVMVwzs0xs8b+en0JTXWi6nB5i8u5vMXlB9yfl59HelZ6YeFv2bWFrJws9uTtYU/ungO+ZudmszNvL8458l3+nxcKvu67H8Dh2LcT5PB9PWinaN/9hbc1RBN0Dv4Zl7WaVWr65XX9VvAlZWb9gH4Axx9/vMdppKIKDwunXtV61Ktaj9b1W3sdRyQgeH4YgnNuvHMu0TmXGBMT43UcEZGg4XnBi4iIf6jgRUSClN8K3swmAf8FmplZqpn9w1/rEhGRv/LnUTS9/fXaIiJyeBqiEREJUip4EZEgpYIXEQlSATXZmJmlAetLuXhdYGsZxilLylY6ylY6ylY6FTXbCc65Ij9EFFAFfzTMLPlQ8zF4TdlKR9lKR9lKJxizaYhGRCRIqeBFRIJUMBX8eK8DFEPZSkfZSkfZSifosgXNGLyIiBwomPbgRURkPyp4EZEgVeEL3swuNrPVZrbGzO7zOs/+zCzFzH4wsyVm5vm5CM3sFTPbYmbL97uvtpl9YWY/+77WCqBsQ8xsg2/7LTGzzh7kamRms83sRzNbYWZ3+O73fLsVky0Qtlukmc03s6W+bI/67o8zs+99v6/vmFnlAMr2mpmt22+7xZd3tv0yhpvZYjP7xHe7dNvNOVdhL0A4sBZoAlQGlgLNvc61X74UoK7XOfbLcw7QFli+333/Bu7zXb8PeDKAsg0B7vZ4mx0HtPVdrwb8BDQPhO1WTLZA2G4GRPuuRwDfA6cBU4ArffePA/oHULbXgJ5ebrf9Mt4FvA184rtdqu1W0ffgOwBrnHO/OOf2ApOBbh5nCljOuTnAHwfd3Q143Xf9deDv5RrK5xDZPOec+905t8h3PRNYCTQkALZbMdk85wrs9N2M8F0ccB4w1Xe/V9vtUNkCgpnFApcAL/tuG6XcbhW94BsCv+13O5UA+R/cxwEzzWyh79yzgai+c+533/VNQH0vwxThNjNb5hvC8WT4aB/fSeQTKNjjC6jtdlA2CIDt5htmWAJsAb6g4K/t7c65XN9TPPt9PTibc27fdhvq226jzayKF9mAZ4B7gXzf7TqUcrtV9IIPdGc559oC/wfcambneB2oOK7g77+A2ZMBXgBOBOKB34GnvApiZtHAe8Cdzrkd+z/m9XYrIltAbDfnXJ5zLh6IpeCv7VO8yFGUg7OZWUvgfgoytgdqA4PKO5eZdQG2OOcWlsXrVfSC3wA02u92rO++gOCc2+D7ugX4gIL/yQPNZjM7DsD3dYvHeQo55zb7fhHzgZfwaPuZWQQFBTrROfe+7+6A2G5FZQuU7baPc247MBs4HahpZvtONOT57+t+2S72DXk559we4FW82W5nAl3NLIWCIefzgGcp5Xar6AW/ADjZ9w5zZeBK4COPMwFgZlXNrNq+68CFwPLil/LER8D1vuvXAx96mOUA+wrUpzsebD/f+OcEYKVz7un9HvJ8ux0qW4Bstxgzq+m7fgxwAQXvEcwGevqe5tV2Kyrbqv3+wTYKxrjLfbs55+53zsU65xpT0GdfOeeuprTbzet3i8vg3ebOFBw9sBZ40Os8++VqQsFRPUuBFYGQDZhEwZ/sORSM4/2DgvG9WcDPwJdA7QDK9ibwA7CMgkI9zoNcZ1Ew/LIMWOK7dA6E7VZMtkDYbq2Bxb4My4FHfPc3AeYDa4B3gSoBlO0r33ZbDryF70gbry5AEn8eRVOq7aapCkREglRFH6IREZFDUMGLiAQpFbyISJBSwYuIBCkVvIhIkFLBS1Ays52+r43N7Koyfu0HDro9ryxfX6SsqOAl2DUGjqjg9/vE4KEcUPDOuTOOMJNIuVDBS7AbAZztm997oG+SqZFmtsA3qdTNAGaWZGZzzewj4EfffdN8E8Wt2DdZnJmNAI7xvd5E3337/low32svt4LzAFyx32t/bWZTzWyVmU30fVpSxK8Ot6ciUtHdR8Hc6F0AfEWd4Zxr75st8Dszm+l7blugpXNune/2jc65P3wfZ19gZu855+4zs9tcwURVB+tBwQRfbYC6vmXm+B5LAFoAG4HvKJhz5Nuy/3ZF/qQ9eAk1FwLX+aaK/Z6CKQdO9j02f79yB7jdzJYC/6NgUruTKd5ZwCRXMNHXZuAbCmYm3Pfaqa5gArAlFAwdifiV9uAl1BgwwDn3+QF3miUBuw66fT5wunNut5l9DUQexXr37Hc9D/3uSTnQHrwEu0wKTme3z+dAf980u5hZU99snwerAWzzlfspFJzSbZ+cfcsfZC5whW+cP4aC0xDOL5PvQqQUtBchwW4ZkOcbanmNgrm1GwOLfG90plH06c8+A24xs5XAagqGafYZDywzs0WuYCrXfT6gYM7zpRTM8nivc26T7x8IkXKn2SRFRIKUhmhERIKUCl5EJEip4EVEgpQKXkQkSKngRUSClApeRCRIqeBFRILU/wPW5PyuTIsW8QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU4kz7QRS5AO",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W66BTEUZGh4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLogisticRegression():\n",
        "\t\"\"\"\n",
        "\tMy implementation of Logistic Regression.\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tpass\n",
        "\n",
        "\tdef sigmoid(self,z):\n",
        "\t\t\"\"\"\n",
        "\t\tFind the sigmoid value of z\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tz : 1-dimensional numpy array of shape (n_samples,)\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tvalue of z in sigmoid function\n",
        "\t\t\"\"\"\n",
        "\t\treturn 1/(1+np.exp(-z))\n",
        "\t\n",
        "\tdef cost_diff(self,X,y,theta):\n",
        "\t\t\"\"\"\n",
        "\t\tFind Log Loss error in current model parameters\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tX : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "\t\ttheta : Value of theta at which derivative of cost has to be found\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tderv : derivative of cost at the value theta\n",
        "\t\t\"\"\"\n",
        "\t\tX_trans=np.transpose(X)\t\t\t\t\t\t\t\t\t\t                       # Transpose of vector X\n",
        "\t\t\n",
        "\t\tderv =(X_trans.dot(self.sigmoid(X.dot(theta))-y))\t\t\t\t         # Calculates X` * ( sigmoid(X*theta) - y )\n",
        "\t\treturn derv\n",
        "\n",
        "\t\n",
        "\tdef gradient_descent(self,X,y,epochs=100,alpha=0.01):\n",
        "\t\t\"\"\"\n",
        "\t\tFinding theta using the gradient descent model\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tX : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "\t\tepochs : Number of times gradient descent has to run\n",
        "\n",
        "\t\talpha : Learning rate of gradient descent\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\ttheta : Calculated value of theta on given test set (X,y) with learning rate alpha \n",
        "\t\t\"\"\"\n",
        "\t\tm=len(y)\n",
        "\t\ttheta=np.transpose(np.array([0]*len(X[0])))                     # created a column vector theta of length equal to number of features in X with all the initial values 0\n",
        "\t\t\n",
        "\t\tfor i in range(epochs):\n",
        "\t\t  theta=theta-(alpha/m)*self.cost_diff(X,y,theta)\n",
        "\t\t\n",
        "\t\treturn theta\n",
        "\n",
        "\tdef fit(self, X, y):\n",
        "\t\t\"\"\"\n",
        "\t\tFitting (training) the logistic model.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tX : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
        "\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tself : an instance of self\n",
        "\t\t\"\"\"\n",
        "\t\tself.theta = self.gradient_descent(X,y,200,0.01)              # using the gradient descent method with given number of epochs and learning rate\n",
        "\n",
        "\t\t# fit function has to return an instance of itself or else it won't work with test.py\n",
        "\t\treturn self\n",
        "\n",
        "\tdef predict(self, X):\n",
        "\t\t\"\"\"\n",
        "\t\tPredicting values using the trained logistic model.\n",
        "\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tX : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.\n",
        "\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\ty : 1-dimensional numpy array of shape (n_samples,) which contains the predicted values.\n",
        "\t\t\"\"\"\n",
        "\t\ty=self.sigmoid(X.dot(self.theta))\n",
        "\t\n",
        "\t\t# return the numpy array y which contains the predicted values\n",
        "\t\treturn y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOUVjO6MSZBi",
        "colab_type": "text"
      },
      "source": [
        "# Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdbZwPiFGwiK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5e04d0c6-4fad-455b-a72d-ef669eb12e57"
      },
      "source": [
        "Xtrain = np.array([[1, 2, 3], \n",
        "                   [4, 5, 6]])\n",
        "ytrain = np.array([1, 2])\n",
        "\n",
        "Xtest = np.array([[7, 8, 9]])\n",
        "ytest = np.array([3])\n",
        "\n",
        "print('Linear Regression')\n",
        "\n",
        "linear = MyLinearRegression()\n",
        "linear.fit(Xtrain, ytrain)\n",
        "\n",
        "ypred = linear.predict(Xtest)\n",
        "\n",
        "print('Predicted Values:', ypred)\n",
        "print('True Values:', ytest)\n",
        "\n",
        "# print('Logistic Regression')\n",
        "\n",
        "# logistic = MyLogisticRegression()\n",
        "# logistic.fit(Xtrain, ytrain)\n",
        "\n",
        "# ypred = logistic.predict(Xtest)\n",
        "\n",
        "# print('Predicted Values:', ypred)\n",
        "# print('True Values:', ytest)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Regression\n",
            "Predicted Values: [3.47084775]\n",
            "True Values: [3]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}